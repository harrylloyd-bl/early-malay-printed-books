{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a98a268-46ef-480c-ab8f-d4dd116e1818",
   "metadata": {},
   "source": [
    "# Extracting catalogue entries from the Early Malay Printed Books catalogue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19a2fe0-c80a-49b4-9153-02564b184992",
   "metadata": {},
   "source": [
    "Collaboration with Annabel Gallop and Adi Keinan-Schoonbaert to create catalogue entries from the OCR of the Early Malay Printed Books catalogue (EMP). Match the extracted entries to a set of works AG is digitising to provide skeleton metadata records as part of the digitisation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3409d7c0-cc62-4272-8dc8-9b4411d34ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "import json\n",
    "from random import sample\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import pymupdf\n",
    "from rapidfuzz import fuzz, utils, process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946f89f4-c3df-4b2f-9d2f-dfff9e6fc7fa",
   "metadata": {},
   "source": [
    "## Extract Description section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe9a0eb-a1d3-47c3-b000-f90e3693dfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = pymupdf.open(\"../data/raw/emp.pdf\") # open a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd94e35-b7a6-438d-a5f5-b287f52b82b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cd2fc8-a27f-466d-b847-7b708dcf85a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = {\"desc\": {}, \"bl_list\": {}, \"titles\": {}}\n",
    "for i, page in enumerate(doc):\n",
    "    i = i + 1  # Just for ease when comparing indexing to the pdf pages\n",
    "    # Printed page numbers are the numbers printed on the page (from title page, then i - 858)\n",
    "    # Actual page numbers are the 1 - 886 numbers of the pages in the pdf, do not correspond to number on the page\n",
    "    # Remember that all actual page numbers in the pdf are one greater than the Python indexing\n",
    "    if i == 1:\n",
    "        section = None\n",
    "    if i == 126:  # Page 98\n",
    "        section = \"desc\"\n",
    "    if i == 596:  # Page 568\n",
    "        section = None\n",
    "    if i == 711:  # Page 683\n",
    "        section = \"titles\"\n",
    "    if i == 802:  # Page 774\n",
    "        break\n",
    "\n",
    "    if section:\n",
    "        page_num = i - 28\n",
    "        page_text = page.get_text() # get plain text (is in UTF-8)\n",
    "        text[section][i] = page_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e080da-cbf5-45bf-8cc6-a268af600d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(text[\"desc\"]) == 470\n",
    "assert len(text[\"titles\"]) == 91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a40deb4-01af-4bac-ae64-e3e07b9489bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_desc = \"\"\n",
    "for k, v in text[\"desc\"].items():\n",
    "    full_desc += v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b22db0-a259-44f8-b3fe-2b55735522c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(full_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a7175f-94b6-4e6e-9b26-c7ed0b545101",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/interim/full_description.txt\", \"w\", encoding=\"utf8\") as f:\n",
    "    f.write(full_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ee0861-3026-414b-82a4-4ae433a62cd4",
   "metadata": {},
   "source": [
    "### Tidy desc page text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35e1ebe-db9c-4253-ad42-a5487f3f0b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_header = []\n",
    "for i in range(126, 596, 2):\n",
    "    early_header.append(text[\"desc\"][i].split(\"\\n\")[0])\n",
    "\n",
    "desc_header = []\n",
    "for i in range(127, 597, 2):\n",
    "    desc_header.append(text[\"desc\"][i].split(\"\\n\")[0])\n",
    "\n",
    "has_page_num = []\n",
    "for i in range (126, 595):\n",
    "    has_page_num.append(text[\"desc\"][i].count(str(i - 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98995ccc-d85e-40c9-8880-0f96bdca162d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(has_page_num).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad68e15-090b-49d1-a7a4-4248ba5a282b",
   "metadata": {},
   "source": [
    "I've investigate the below, in each instance the header was not transcribed, rather than transcribed in the wrong place, so current logic to remove it if present holds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553bbacf-2d28-4e60-8037-2cc06d958b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(i, e) for i, e in enumerate(early_header) if \"EARL\" not in e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7f8336-3020-4e4e-b936-e06f13678342",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_head_counts = pd.Series([e for e in early_header if \"EARL\" in e]).value_counts()\n",
    "print(emp_head_counts.sum())\n",
    "emp_head_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c459d716-a3aa-4e59-877d-42bfa10437cd",
   "metadata": {},
   "source": [
    "The below is just some extra mistranscribed lines due to lines at the top of the photocopy, DESCRIPTION appears on the third line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bf4ceb-e14a-46c1-b9a0-5e4d9800bdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(i, d) for i, d in enumerate(desc_header) if \"DESC\" not in d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5902cee-4a7b-491d-b15f-ecff1881e37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([d for d in desc_header if \"DESC\" in d]).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0eb6e7f-a6e8-40f2-aabc-8302de504e63",
   "metadata": {},
   "source": [
    "#### Pre-treat mistranscriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce8445b-43a2-4a9c-a7d5-619a2f3e615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad header\n",
    "if text[\"desc\"][383][0] == \"_\":\n",
    "    text[\"desc\"][383] = text[\"desc\"][383][10:]\n",
    "assert text[\"desc\"][383][:5] == \"DESCR\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d22526e-69a6-41f5-90ce-e4b3d3d3f35e",
   "metadata": {},
   "source": [
    "#### Parsing the first page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471352f6-45a6-4b5a-8be9-d6f2d5b5efbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "split = text[\"desc\"][126].split(\"\\n\")\n",
    "if split[1] == \"It should be assumed that the author/editor \":\n",
    "    text[\"desc\"][126] = \"\\n\".join(split[9:49] + split[58:])\n",
    "assert text[\"desc\"][126][:5] == \"Abbas\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699bf135-8528-4a13-8dde-000aed540e7b",
   "metadata": {},
   "source": [
    "#### Parse columns on remaining pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0a2dd0-4d66-447f-8cdd-cc141912498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_desc_page(page, page_num):\n",
    "    trim_space = page.replace(\" \\n\", \"\\n\")\n",
    "    split = trim_space.split(\"\\n\")\n",
    "    lines = [l for l in split if l]\n",
    "    if \"DESC\" in lines[0] or \"EARL\" in lines[0]:\n",
    "        lines = lines[1:]\n",
    "\n",
    "    # Only 20 out of 469 pages where count != 1\n",
    "    if lines.count(page_num) == 1:\n",
    "        lines.remove(page_num)\n",
    "\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250416c8-c2c9-4a8e-aa37-e560b9a3d626",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_desc_pages = []\n",
    "for i in range(126, 596):\n",
    "    page_num = str(i - 28)\n",
    "    page = text[\"desc\"][i]\n",
    "    processed_desc_pages.append(process_desc_page(page=page, page_num=page_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0a2745-f2fa-4ffb-b199-16e46fa0b23e",
   "metadata": {},
   "source": [
    "#### Compare processed desc pages to ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0410af-6f74-421e-9d6a-dd2f29b3bbc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, p in enumerate(processed_desc_pages[:5]):\n",
    "    with open(f\"../data/processed/ground_truth/p{i+1}_column_parse.txt\", encoding=\"utf8\") as f:\n",
    "        gt = [l.strip(\"\\n\") for l in f.readlines()]\n",
    "        print(i + 1)\n",
    "        print([a for a,b in zip(gt, p) if a!=b])\n",
    "        assert gt == p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327e654f-18eb-4c13-90c1-0fac277ca4e3",
   "metadata": {},
   "source": [
    "## Extract catalogue entries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606ff8f1-1436-4580-a4da-744fae72771e",
   "metadata": {},
   "source": [
    "### Tidy title page text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383a7057-000a-4715-8513-195fadaa76b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_early_header = []\n",
    "for i in range(713, 802, 2):\n",
    "    titles_early_header.append(text[\"titles\"][i].split(\"\\n\")[0])\n",
    "\n",
    "titles_title_header = []\n",
    "for i in range(712, 802, 2):\n",
    "    titles_title_header.append(text[\"titles\"][i].split(\"\\n\")[0])\n",
    "\n",
    "titles_has_page_num = []\n",
    "for i in range (711, 802):\n",
    "    titles_has_page_num.append(text[\"titles\"][i].count(str(i - 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5126a5b-3dbc-45ee-84d4-cfe5b3149318",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(titles_has_page_num).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2f6b61-8d61-475e-a680-fd4fab8872d5",
   "metadata": {},
   "source": [
    "I've investigated the below, the page has been mis-transcribed as having two columns and needs correcting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ca8a6f-2e93-4d15-8d0c-7d7a25b1918c",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(i, e) for i, e in enumerate(titles_early_header) if \"EARL\" not in e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63db9dc2-cc8a-4941-8805-1faf4761fdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_head_counts = pd.Series([e for e in titles_early_header if \"EARL\" in e]).value_counts()\n",
    "print(emp_head_counts.sum())\n",
    "emp_head_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1313d343-7cb8-42aa-8695-44b47b2628b2",
   "metadata": {},
   "source": [
    "The below is just some extra mistranscribed lines due to lines at the top of the photocopy, DESCRIPTION appears on the third line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6ea9f2-1e95-4c87-847f-821c56bc0985",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(i, d) for i, d in enumerate(titles_title_header) if \"LES\" not in d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e8c749-c865-42f8-97e0-67a8734922be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([d for d in titles_title_header if \"LES\" in d]).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1a6e66-87a0-4c5d-92d5-679d6b0fd406",
   "metadata": {},
   "source": [
    "#### Pre-treat mistranscriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13d709c-0845-4d82-8bf5-09bcf3b7c5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad reading order\n",
    "text[\"titles\"][724] = text[\"titles\"][724].replace(\"\\nTITI..ES \", \"\")\n",
    "text[\"titles\"][768] = text[\"titles\"][768].replace(\"\\nTfILES \", \"\")\n",
    "text[\"titles\"][770] = text[\"titles\"][770].replace(\"\\nTI1LES \", \"\")\n",
    "text[\"titles\"][774] = text[\"titles\"][774].replace(\"\\nTITLES \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d583bf-3891-4065-a4d3-5f9727481bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text[\"titles\"][720][:1680]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3eb5d2-ded0-4b3b-8e93-ad771905d98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# semi-accidental double column\n",
    "# the excluded section contains no main works among collected ceretera/cerita/ceritera/cetera\n",
    "if text[\"titles\"][720][-5:] == \"692 \\n\":\n",
    "    text[\"titles\"][720] = text[\"titles\"][720][:1680]\n",
    "    \n",
    "# accidental double column\n",
    "# the small amount of extracted is the only main work among collected ceretera/cerita/ceritera/cetera\n",
    "if text[\"titles\"][721][:5] == '\"Chre':\n",
    "    text[\"titles\"][721] = text[\"titles\"][721][2613:2657].replace(\"\\n\", \"\")\n",
    "\n",
    "# accidental double columns\n",
    "# the small amount of extracted is the only main work among collected ceretera/cerita/ceritera/cetera\n",
    "if text[\"titles\"][722][:5] == \"TI1LE\":\n",
    "    text[\"titles\"][722] = \"Cerita Rampai-Rampai 1916 (t) - see also Abu Nawas 1917\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811299b7-611d-425f-8fe5-07c47e225c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "text[\"titles\"][722][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863a7875-0d25-468d-87d3-8035f787f86b",
   "metadata": {},
   "source": [
    "### Create list of titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb13082-e636-4f25-8cca-4a210c0c066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/processed/ground_truth/raw_title_list_p683.txt\", encoding=\"utf8\") as f:\n",
    "    raw_title_gt_lines_683 = [x.strip(\"\\n\") for x in f.readlines()]\n",
    "\n",
    "with open(\"../data/processed/ground_truth/raw_title_list_p688.txt\", encoding=\"utf8\") as f:\n",
    "    raw_title_gt_lines_688 = [x.strip(\"\\n\") for x in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae2d9d1-10f5-4cac-833c-53c371b910c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_titles_page(page, page_num):\n",
    "    # trim_space = page.replace(\" \\n\", \"\\n\")\n",
    "    continuing_date_p = re.compile(r\"\\n(\\d{4,4})\")\n",
    "    continue_date = continuing_date_p.sub(r\"\\1\", page)\n",
    "    continue_dash = continue_date.replace(\"\\n-\\n\", \"- \").replace(\"-\\n\", \"- \")\n",
    "    continue_a = continue_dash.replace(\"\\na \", \"a \").replace(\"\\na, \", \"a, \")\n",
    "    split = continue_a.split(\"\\n\")\n",
    "    lines = [l.strip() for l in split if l]\n",
    "\n",
    "    # Only 20 out of 469 pages where count != 1\n",
    "    if lines.count(page_num) == 1:\n",
    "        lines.remove(page_num)\n",
    "    \n",
    "    lines = lines[1:]\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54993a2e-b8e1-4935-b22d-8e27b5842692",
   "metadata": {},
   "outputs": [],
   "source": [
    "text[\"titles\"][711][833:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47feed79-c766-47dc-9c4e-3acbc5967242",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_title_pages = []\n",
    "for i in range(711, 802):\n",
    "    page_num = str(i - 28)\n",
    "    page = text[\"titles\"][i]\n",
    "    processed_title_pages.append(process_titles_page(page=page, page_num=page_num))\n",
    "\n",
    "processed_title_pages[0] = processed_title_pages[0][9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed52782-3329-4ca0-965f-0a4ec01eaa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(processed_title_pages[5]), len(raw_title_gt_lines_688)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bb3074-b30d-4911-b513-123ae9c81b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_titles = []\n",
    "for p in processed_title_pages:\n",
    "    all_titles.extend(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d52005f-8029-44f9-98c7-24013efb44f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13457a44-37aa-45a5-93a4-1c2e3c15e49f",
   "metadata": {},
   "source": [
    "#### Manual extraction of lines that should be concatenated but haven't"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c745b7-a68f-4ebd-995e-05f570533e4a",
   "metadata": {},
   "source": [
    "I went through all 4.3k title lines in all_titles and checked whether the line was a title or was a continuation of the previous line. Extracted all the lines that should be continued into lines_to_concatenate_with_text.  \n",
    "\n",
    "Decided this was a good trade-off as not too many lines to extract (~4% error) vs adding new rules to find these errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd038167-f6e5-4248-8062-93104850b4f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Used this to check all_titles 1k at a time, scanning quickly through the first letters of titles to check\n",
    "# took maybe half an hour\n",
    "[str(i + 0) + \" \" + t for i,t in enumerate(all_titles[0:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a18fb9-6208-414c-bcdc-9b88d3f20c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/processed/lines_to_concatenate_with_text.txt\", encoding=\"utf8\") as f:\n",
    "    lines = [l.strip(\"\\n\").split(\"\\t\") for l in f.readlines()]\n",
    "    bad_line_ids, bad_line_texts = [int(l[0]) for l in lines], [l[1] for l in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10e8743-f23f-4644-936f-2aed85d326c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the text of the lines we're going to merge with other lines matches our expectation\n",
    "assert all([all_titles[line_id] == text for line_id, text in zip(bad_line_ids, bad_line_texts)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c909d7e-3f17-4678-9bd1-c5ee269b1127",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check I've coded the lines right\n",
    "for l in bad_line_ids:\n",
    "    print(l)\n",
    "    print(\"\\n\".join(all_titles[l-2:l+3]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ea7d77-b36a-42af-84ab-c0a537a71f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_titles_concatenated = copy(all_titles)\n",
    "for l in bad_line_ids[::-1]:\n",
    "    all_titles_concatenated[l-1] = all_titles_concatenated[l-1] + \" \" + all_titles_concatenated[l]\n",
    "\n",
    "all_titles_corrected = []\n",
    "for i, t in enumerate(all_titles_concatenated):\n",
    "    if i not in bad_line_ids:\n",
    "        all_titles_corrected += [t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e14094c-4429-44a8-973e-09811c6d5014",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_titles_corrected[62]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7110511e-eea6-4f1d-8f94-6fe548d25caf",
   "metadata": {},
   "source": [
    "#### Select only main works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77779db3-d398-42d9-ab14-dbeb81544739",
   "metadata": {},
   "outputs": [],
   "source": [
    "see_re = re.compile(r\"see(?! also)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c432ca6b-b2db-4dc5-8bf5-87cf20825b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "see_re.search(\"hello see also\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddb793a-027b-43fc-ae96-524f64d6979d",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_works = []\n",
    "for title in all_titles_corrected:\n",
    "    if see_re.search(title) or \"look\" in title:\n",
    "        continue    \n",
    "    else:\n",
    "        main_works.append(title)\n",
    "\n",
    "# This cf is the only incorrect one not caught by the 'see' regex\n",
    "main_works.remove('Adab Kesopanan bagi Orang Muda-Muda Anak yang Bangsawan - cf Adab aI-Fatiy 1916')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8532a39-be9c-4544-bec5-92a589e1950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(main_works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e352b89-1ed1-44de-8a5a-ad964530eddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# template for gt based on first ~30 works\n",
    "\"\"\"\n",
    "with open(\"../data/processed/ground_truth/28_main_titles.txt\", \"w\", encoding=\"utf8\") as f:\n",
    "    for w in main_works[:30]:\n",
    "        f.write(w + \"\\n\")\n",
    "\"\"\"\n",
    "with open(\"../data/processed/ground_truth/28_main_titles.txt\", encoding=\"utf8\") as f:\n",
    "    gt_main_works = [l.strip(\"\\n\") for l in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75870664-e4d0-4b62-a06e-a7ed2aedf3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all([w == gt_w for w, gt_w in zip(main_works, gt_main_works)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4531eb-e825-4fc1-bae5-6554ea20f335",
   "metadata": {},
   "outputs": [],
   "source": [
    "works_date_re = re.compile(r\"[ Â±]{1,2}[l0-9]{4,4}\")\n",
    "trailing_a_re = re.compile(r\" a( |$)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b518c11c-ba4f-4458-851b-0c8d8c9f28b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_work_short_titles = []\n",
    "for w in main_works:\n",
    "    no_date = re.split(works_date_re, w)[0]\n",
    "    no_a_ed = re.split(trailing_a_re, no_date)[0]\n",
    "    clean_short_title = no_a_ed\n",
    "    main_work_short_titles.append(clean_short_title)\n",
    "\n",
    "# Some work are duplicated due to line breaks converting \"see <name of work>\" to \"see\\n<name of work>\", in which case the work gets picked up again\n",
    "main_work_short_title_df = pd.Series(main_work_short_titles).drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef8e897-29d5-4718-9727-46a1efd7930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_work_short_title_df.to_csv(\"../data/processed/all_short_titles.csv\", encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b7d3f7-7c06-4f8b-8a47-8cfc9038367c",
   "metadata": {},
   "source": [
    "#### Compare main works to titles from BL shelf list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dabe81-37a6-4c26-aeba-cca7b225fe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aac_list = pd.read_csv(\"../data/external/Proudfoot-BL collection-6.10.25.csv\", header=None, names=[\"shelfmark\", \"short_title\", \"year\"], usecols=[0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f673b4f2-07a9-4169-acd7-58c54ce851b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trailing_abc_re = re.compile(r\" [abc] ?$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8030beb6-47d8-477d-a1d8-80de85cc4d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_short_title(row):\n",
    "    no_date = re.split(works_date_re, row[\"short_title\"])[0]\n",
    "    no_a_ed = re.split(trailing_abc_re, no_date)[0]\n",
    "    clean_short_title = no_a_ed\n",
    "    return clean_short_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f17b53-5e22-462d-b6bd-7caf34f0c851",
   "metadata": {},
   "outputs": [],
   "source": [
    "aac_list[\"short_title_no_year\"] = aac_list.apply(clean_short_title, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b74be19-8df5-43b5-a553-c29731ef9fde",
   "metadata": {},
   "source": [
    "435 unique titles in the AAC list. 174 of these don't appear identically in the main works list extracted from the titles list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69fbf80-4cca-4e68-b2f6-407967ba9818",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matched_works = [(w, w) for w in aac_list[\"short_title_no_year\"].unique() if w in main_work_short_titles]\n",
    "missing_works = [w for w in aac_list[\"short_title_no_year\"].unique() if w not in main_work_short_titles]\n",
    "len(missing_works), len(aac_list[\"short_title_no_year\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829d5588-c407-4ec8-80d0-4cfa68d1312c",
   "metadata": {},
   "source": [
    "Check all missing works from the AAC list against the entire main works list, using the basic rapidfuzz ration returning up to 3 matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01c56ac-cad6-421e-b045-c38ee726596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_work_matches = []\n",
    "for w in missing_works:\n",
    "    matches = process.extract(w, main_work_short_titles, scorer=fuzz.ratio, limit=3, processor=utils.default_process)\n",
    "    missing_work_matches.append([w, matches])\n",
    "\n",
    "accepted_matches = []\n",
    "failed_matches = []\n",
    "for w, matches in missing_work_matches:\n",
    "    if matches[0][1] >= 90:\n",
    "        accepted_matches.append((w, matches[0][0], matches[0][1]))\n",
    "    else:\n",
    "        failed_matches.append((w, matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504941de-0f8d-4492-b5c3-5ed499e18513",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(missing_works) - len(accepted_matches), len(accepted_matches), len(missing_works), len(aac_list[\"short_title_no_year\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7091806f-04f7-449d-8ec6-1de6ec6fbf47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accepted_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1081399c-a37a-444d-8c05-e6e6c11356cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "failed_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb99621-4aa5-4e7f-bc18-9dd826ecacc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_works += [(w[0], w[1]) for w in accepted_matches]\n",
    "matched_works.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fb5ce5-4971-4b13-bf0f-11d4689e52a9",
   "metadata": {},
   "source": [
    "#### Matched work ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30557bc2-77cc-4d62-8c7a-0825943e977c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = sample(matched_works, 50)\n",
    "# with open(\"../data/processed/ground_truth/50_matched_works.txt\", \"w\", encoding=\"utf8\") as f:\n",
    "#     for s in sample:\n",
    "#         f.write(f\"{s[0]}, {s[1]}\\n\")\n",
    "\n",
    "with open(\"../data/processed/ground_truth/50_matched_works.txt\", encoding=\"utf8\") as f:\n",
    "    gt_titles = [tuple(l.strip(\"\\n\").split(\", \")) for l in f.readlines()]\n",
    "    # gt_titles = [(w[0], w[1]) for w in ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72144a2-d39c-4773-81c0-4edfd9702751",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all([t in matched_works for t in gt_titles])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716acacf-6c0e-4113-8301-12b36094d511",
   "metadata": {},
   "source": [
    "### Create catalogue entry ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377c6216-2db4-42e6-8d4e-06bcc6975331",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_processed_lines = []\n",
    "line_page_lookup = {}\n",
    "line_count = 0\n",
    "for i, p in enumerate(processed_desc_pages):\n",
    "    all_processed_lines += p\n",
    "\n",
    "    for j, l in enumerate(p):\n",
    "        line_page_lookup[j + line_count] = i + 98\n",
    "    \n",
    "    line_count += len(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa04822-fee8-451f-8fda-4b8d9340c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate OCR errors from text in the GT\n",
    "entry_gt = {\n",
    "    \"Abbas\": all_processed_lines[1:42],\n",
    "    \"Abdau\": all_processed_lines[43:91],\n",
    "    \"Abdullah\": all_processed_lines[92:572],\n",
    "    \"Abdullah dan Sabat\": all_processed_lines[573:677],\n",
    "    \"AbdulMuluk\": all_processed_lines[678:1091]\n",
    "}\n",
    "\n",
    "# with open(\"../data/processed/ground_truth/entry.json\", \"w\", encoding=\"utf8\") as f:\n",
    "#     json.dump(entry_gt, f, indent=4)\n",
    "\n",
    "# with open(\"../data/processed/ground_truth/entry.json\", encoding=\"utf8\") as f:\n",
    "#     entry_gt = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d99353-0ed4-4c2f-b731-0f445fbbfb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, lines in entry_gt.items():\n",
    "    print(lines[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b5ef4d-e1ab-40c6-a639-0d0697e1b53b",
   "metadata": {},
   "source": [
    "### Search for main work short titles in all description lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db50b37-a923-4be7-9cff-b147afe54ba4",
   "metadata": {},
   "source": [
    "#### Longest catalogue entry analysis to provide limit for difference between min_line and max_line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505f3e46-2837-41ee-8de8-446e729fb13a",
   "metadata": {},
   "source": [
    "main_work_short_titles contains (to a degree of accuracy) all the short titles in the description section of the EMP. Use these to split up the lines of the description section into individual catalogue entries. Due to the quality of OCR in the description section I expect not to find a reasonable number of the main work short titles. Will have to use fuzzy string matching/manual intervention for the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82147e0a-e227-4957-9e43-67fce328eeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_locs = []\n",
    "title_line_tracker = 0  # This has to be accurate for it to work, otherwise can get too large too quickly\n",
    "# only use title_line_tracker as validity check once location of all headings confirmed\n",
    "\n",
    "# TODO work out longest entry to use that as a limit on how far ahead to search for the next heading\n",
    "# Answer: 2000 is ~2x the 95% of +ve valid hits using naive search algorithm (which includes some very large incorrect values)\n",
    "\n",
    "for w in main_work_short_title_df:\n",
    "    line_window = all_processed_lines[title_line_tracker: title_line_tracker + 2000]\n",
    "    if w in line_window:\n",
    "        line_loc = line_window.index(w) + title_line_tracker\n",
    "        title_locs.append((w, None, line_loc, title_line_tracker, title_line_tracker + 2000))\n",
    "        title_line_tracker = line_loc\n",
    "    else:\n",
    "        title_locs.append((w, None, None, title_line_tracker, title_line_tracker + 2000))\n",
    "\n",
    "title_loc_df = pd.DataFrame(title_locs, columns=[\"short_title\", \"short_title_ocr_alias\", \"line_start\", \"min_line\", \"max_line\"])\n",
    "title_loc_df[\"line_start\"] = title_loc_df[\"line_start\"].astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fa6202-d974-426d-84c9-2262229bc46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_lengths = title_loc_df[\"line_start\"].iloc[1:] - title_loc_df[\"line_start\"].shift(1).dropna()\n",
    "valid_lengths[valid_lengths >= 0].dropna().describe(percentiles=[0.9,0.95])\n",
    "valid_lengths[valid_lengths >= 0].dropna().hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3268f256-0e07-41d2-a7e2-de0c69ea445e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just shy of 600 missing values at the moment\n",
    "title_loc_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6146f251-0579-4932-a486-15304ae8f94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_of_sequence_match = title_loc_df[\"line_start\"].dropna().iloc[:-1][~((title_loc_df[\"line_start\"].dropna().iloc[:-1] - title_loc_df[\"line_start\"].dropna().shift(-1)).dropna() < 0)]\n",
    "assert out_of_sequence_match.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda8a283-13b4-4d9d-bd7c-c885c46794f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_line(row, all_lines):\n",
    "    possible_lines = all_lines[row[\"min_line\"]:row[\"max_line\"]]\n",
    "    if row[\"line_start\"] is pd.NA:\n",
    "        nearest_line = process.extract(row[\"short_title\"], possible_lines, scorer=fuzz.ratio, limit=1, processor=utils.default_process)[0]\n",
    "        return (nearest_line[0], nearest_line[1], nearest_line[2] + row[\"min_line\"])\n",
    "    else:\n",
    "        return (row[\"short_title\"], 100.0, row[\"line_start\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faac4bd-d0f0-4d44-b80c-3ad82c0a6525",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_loc_df.iloc[480:520]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42386092-23fb-45e1-8913-fa58811f07c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_apply = title_loc_df.apply(find_nearest_line, all_lines=all_processed_lines, axis=1)\n",
    "title_loc_df[\"nearest_line\"] = nearest_apply.apply(lambda x: x[0])\n",
    "title_loc_df[\"similarity\"] = nearest_apply.apply(lambda x: x[1])\n",
    "title_loc_df[\"nearest_line_idx\"] = nearest_apply.apply(lambda x: x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1df680-d508-464e-a0db-1a57519beffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# >90% similarity matches for 63.5% of unmatched names\n",
    "title_loc_df[\"similarity\"].describe(percentiles=[0.345,0.6,0.65,0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09802844-bf38-47d7-b5b1-ea3fb61c0efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_loc_df.loc[title_loc_df[\"similarity\"] >= 90, \"short_title_ocr_alias\"] = title_loc_df.loc[title_loc_df[\"similarity\"] >= 90, \"short_title\"]\n",
    "title_loc_df.loc[title_loc_df[\"similarity\"] >= 90, \"line_start\"] = title_loc_df.loc[title_loc_df[\"similarity\"] >= 90, \"nearest_line_idx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca570338-4701-4948-b6e5-618fbdcb63d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After selecting >90% matches, 250 more matches, leaving 324 unmatched\n",
    "title_loc_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8626746-610d-4955-b236-69422e9f7e27",
   "metadata": {},
   "source": [
    "#### Manually check unmatched titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369b8c9b-3885-4b31-bfa1-c2508358b2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_with_adjacent = []\n",
    "for t in title_loc_df.loc[title_loc_df[\"line_start\"].isna()].index:\n",
    "    missing_with_adjacent += [t-1, t, t+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe155a2-a5d8-454a-899a-6ead36c7dcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_with_adjacent_df = title_loc_df.loc[sorted(list(set(missing_with_adjacent)))[:-1]]\n",
    "missing_with_adjacent_df[\"min_line_page\"] = missing_with_adjacent_df[\"min_line\"].map(line_page_lookup)\n",
    "missing_with_adjacent_df.to_csv(\"../data/interim/missing_title_adjacent.csv\", encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d773ae-c5df-41a3-965f-e4f64c6774db",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_with_adjacent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30a6112-6393-469f-bfc9-df2b71e1f714",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_check_df = pd.read_csv(\"../data/interim/missing_title_adjacent_manual_check.csv\", encoding=\"UTF8\", index_col=0)\n",
    "\n",
    "# check all missing titles have been manually checked\n",
    "assert (~manual_check_df[manual_check_df[\"line_start\"].isna()][\"approve\"].isna()).all()\n",
    "\n",
    "# check all line_start match nearest_line_idx\n",
    "assert (manual_check_df.dropna(subset=\"line_start\")[\"line_start\"].astype(int) == manual_check_df.dropna(subset=\"line_start\")[\"nearest_line_idx\"]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc73a46-d6c9-43c3-b813-4b6165a20c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 297 corrected, 29 to exclude\n",
    "manual_check_df[\"approve\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59649c9-7978-48d3-b52a-7c9febcdd40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "manually_approved_df = manual_check_df[manual_check_df[\"approve\"] != -1]\n",
    "manually_approved_idx = manually_approved_df.index\n",
    "to_exclude_idx = manual_check_df[manual_check_df[\"approve\"] == -1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a21f63a-335a-4b74-ba33-245e7b56b9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_loc_df.loc[manually_approved_idx, \"nearest_line\"] = manually_approved_df[\"nearest_line_idx\"].apply(lambda x: all_processed_lines[x])\n",
    "title_loc_df.loc[manually_approved_idx, \"nearest_line_idx\"] = manually_approved_df[\"nearest_line_idx\"]\n",
    "\n",
    "title_loc_df.loc[manually_approved_idx, \"line_start\"] = title_loc_df[\"nearest_line_idx\"]\n",
    "title_loc_df.loc[manually_approved_idx, \"short_title_ocr_alias\"] = title_loc_df[\"nearest_line\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b273288c-7035-4b94-8344-51cfe3009aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_loc_df.drop(index=to_exclude_idx, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be34905-369c-4207-b735-1ac3cfaa9b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_loc_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12143dba-dbad-479b-a5e8-25925a264de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_loc_df[\"entry_start\"] = title_loc_df[\"nearest_line_idx\"]\n",
    "title_loc_df[\"entry_end\"] = title_loc_df[\"nearest_line_idx\"].shift(-1).astype(\"Int64\") - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425cbab1-2a68-4e7a-a656-6090443b21b6",
   "metadata": {},
   "source": [
    "#### Manual fixes identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e821c7-d7b3-4733-bab2-b959c3807eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_loc_df.loc[title_loc_df.query(\"short_title_ocr_alias == 'IlmuFalak'\").index, \"entry_start\"] = 18278 - 2  # Fix an entry starting two lines late due to bad title OCR\n",
    "title_loc_df.loc[title_loc_df.query(\"short_title_ocr_alias == 'Ilmu Bintang'\").index, \"entry_end\"] = 18277 - 2\n",
    "\n",
    "title_loc_df.loc[title_loc_df.query(\"short_title_ocr_alias == 'Sirat al-Mustakim'\").index, \"entry_start\"] = 41676 - 1  # Fix an entry starting two lines late due to bad title OCR\n",
    "title_loc_df.loc[title_loc_df.query(\"short_title_ocr_alias == 'Slraj aI-KalbI'\").index, \"entry_end\"] = 41675 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d30db48-5dc1-4ace-b861-616e1fa175b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_loc_df.loc[title_loc_df.query(\"short_title_ocr_alias == 'Akhbar'\").index, \"entry_end\"] = 2520 - 64\n",
    "title_loc_df.loc[title_loc_df.query(\"short_title == 'Akidat al-Munajjin'\").index, \"entry_start\"] = 2521 - 64  # Fix an entry starting late due to bad title OCR\n",
    "title_loc_df.loc[title_loc_df.query(\"short_title == 'Akidat al-Munajjin'\").index, \"entry_end\"] = 2540 + 1  # Fix an entry starting late due to bad title OCR\n",
    "title_loc_df.loc[title_loc_df.query(\"short_title_ocr_alias == 'Alauddln'\").index, \"entry_start\"] = 2541 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dcb98b-a8c7-4862-93b3-eda18d99b675",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_loc_df.iloc[-1, -1] = 51208  # Manually correct end of final entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee61db6-b930-4bba-9950-ff77f90e8a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_loc_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b19855-6e3c-4316-8f61-5d7c07504bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for gt_title, gt_text in entry_gt.items():\n",
    "    start, end = title_loc_df.query(f\"nearest_line == '{gt_title}'\")[[\"entry_start\", \"entry_end\"]].iloc[0]\n",
    "    extracted_text = all_processed_lines[start + 1:end + 1]\n",
    "    assert gt_text == extracted_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027f2cdd-c970-46bd-8e68-30be3e2d7cb5",
   "metadata": {},
   "source": [
    "Manual fix for a section that hadn't been picked up due to the title_line_tracker being pushed too far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7e23ff-3941-4ab0-a25e-15af8be8e698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual_title_locs = []\n",
    "# manual_title_line_tracker = 28825  # This has to be accurate for it to work, otherwise can get too large too quickly\n",
    "# # only use title_line_tracker as validity check once location of all headings confirmed\n",
    "\n",
    "# # TODO work out longest entry to use that as a limit on how far ahead to search for the next heading\n",
    "# # Answer: 2000 is ~2x the 95% of +ve valid hits using naive search algorithm (which includes some very large incorrect values)\n",
    "\n",
    "# for w in main_work_short_title_df.loc[505:525]:\n",
    "#     line_window = all_processed_lines[manual_title_line_tracker: manual_title_line_tracker + 2000]\n",
    "#     if w in line_window:\n",
    "#         line_loc = line_window.index(w) + manual_title_line_tracker\n",
    "#         manual_title_locs.append((w, None, line_loc, manual_title_line_tracker, manual_title_line_tracker + 2000))\n",
    "#         manual_title_line_tracker = line_loc\n",
    "#     else:\n",
    "#         manual_title_locs.append((w, None, None, manual_title_line_tracker, manual_title_line_tracker + 2000))\n",
    "\n",
    "# manual_title_loc_df = pd.DataFrame(manual_title_locs, columns=[\"short_title\", \"short_title_ocr_alias\", \"line_start\", \"min_line\", \"max_line\"])\n",
    "# manual_title_loc_df[\"line_start\"] = manual_title_loc_df[\"line_start\"].astype(\"Int64\")\n",
    "\n",
    "# manual_nearest_apply = manual_title_loc_df.apply(find_nearest_line, all_lines=all_processed_lines, axis=1)\n",
    "# manual_title_loc_df[\"nearest_line\"] = manual_nearest_apply.apply(lambda x: x[0])\n",
    "# manual_title_loc_df[\"similarity\"] = manual_nearest_apply.apply(lambda x: x[1])\n",
    "# manual_title_loc_df[\"nearest_line_idx\"] = manual_nearest_apply.apply(lambda x: x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e6e024-e5cc-4bf4-918e-c7f77e56d4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_processed_lines[51200:51208]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2aabaf3-f9f5-4327-a10f-10d70cec0149",
   "metadata": {},
   "source": [
    "#### Map titles to canonical titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758c35c7-61ef-4485-b971-c94529769e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_loc_df[\"correct_title\"] = title_loc_df[\"short_title\"]\n",
    "title_loc_df.loc[title_loc_df[title_loc_df[\"short_title\"] == \"I1mu Falak\"].index, \"correct_title\"] = \"Ilmu Falak\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0b9939-8d07-441d-a123-2d381dc486c7",
   "metadata": {},
   "source": [
    "#### Check catalogue entry coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4d3e10-e960-4bc9-aa43-5692fcb56c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Easy manual approval reduces remaining to 81\n",
    "title_loc_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff73d193-de4f-42d2-93e3-6614ac8e607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_lines_set = set()\n",
    "for s in title_loc_df.dropna(subset=\"line_start\").apply(lambda x: set(range(x[\"entry_start\"], x[\"entry_end\"] + 1)), axis=1).values:\n",
    "    entry_lines_set |= s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405bdfe5-1336-4c04-b022-be5e94df8032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all but two lines included in title_loc_df entries\n",
    "print(len(all_processed_lines), len(entry_lines_set))\n",
    "set(range(0, 51207)) - entry_lines_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671dd531-e3a9-455c-8b8c-acd0d35cae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_processed_lines[26005: 26007]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe2b5cd-05e5-47a8-b1de-0d42d0defb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_loc_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25e4d2e-cf8f-4c0f-8d4a-fd0455af2f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_loc_df[\"entry_text\"] = title_loc_df.apply(lambda x: \"\\n\".join(all_processed_lines[x[\"entry_start\"]: x[\"entry_end\"] + 1]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f3cb3b-45c8-4a26-9a13-22d2f69eb5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_entry_text_df = title_loc_df.rename(columns={\"short_title\": \"titles_ocr_short_title\", \"short_title_ocr_alias\": \"desc_ocr_short_title\"})[[\"titles_ocr_short_title\", \"desc_ocr_short_title\", \"correct_title\", \"entry_start\", \"entry_end\", \"entry_text\"]]\n",
    "# prog_report_df.to_csv(\"../data/processed/raw_entry_text.csv\", encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5502a3-99ee-46e0-b503-1fb8ac3fd482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_entry_text = pd.read_csv(\"../data/processed/raw_entry_text.csv\", encoding=\"utf-8-sig\")\n",
    "raw_entry_text_df.loc[24, \"entry_text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd82b0b-7d95-4c71-9b05-4957bee716e5",
   "metadata": {},
   "source": [
    "### Parse ground truth catalogue entry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d646c26-9da9-4d90-9615-23fdc289f132",
   "metadata": {},
   "source": [
    "#### Parse AG ground truth sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f786ff17-a369-4ce4-b90e-017bd3fefdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ag_entry_gt_df = pd.read_csv(\"../data/external/ALEPH_sample_Bollinger_EMP.csv\", encoding=\"utf8\")\n",
    "raw_ag_entry_gt_df.drop(index=2, inplace=True)\n",
    "raw_ag_entry_gt_df = raw_ag_entry_gt_df.iloc[2:]\n",
    "cols = [\"A\", \"E\", \"Q\", \"U\", \"AB\", \"AC\", \"AD\", \"AH\", \"AJ\", \"AQ\", \"AR\", \"CM\"]\n",
    "col_nums = [0, 4, 16, 20, 27, 28, 29, 33, 35, 42, 43, 90]\n",
    "ag_entry_gt_df = raw_ag_entry_gt_df.iloc[:, col_nums].reset_index(drop=True)\n",
    "ag_entry_gt_df.loc[5, \"Bibliography etc. note\"] = \"Proudfoot 1993: San Guo 1892-96\"  # Functionally the same, this is how it's listed in EMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb60660-699f-4061-8731-9bd343e3f5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ag_entry_gt_df.iloc[:, 24:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d34bd9-a6b2-410f-a63b-63a7555499af",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_title_edition = ag_entry_gt_df[\"Bibliography etc. note\"].str.split(\": \").apply(lambda x: x[1]).str.split(\" \").apply(lambda x: (\" \".join(x[:-1]), x[-1]))\n",
    "gt_title_edition = pd.DataFrame(data={\"target_title\": gt_title_edition.apply(lambda x: x[0]), \"target_edition\": gt_title_edition.apply(lambda x: x[1])})\n",
    "gt_title_edition.sort_values(by=\"target_title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8999b6-9c60-471f-b471-c3b61544a552",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_entry_text_df = pd.merge(left=raw_entry_text_df, right=gt_title_edition, left_on=\"correct_title\", right_on=\"target_title\")\n",
    "gt_entry_text_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55770ad-3100-4ab6-a750-1f2ebe89a3cd",
   "metadata": {},
   "source": [
    "#### Create prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e869f717-149f-49b8-8be1-9f67b0a89ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_schema = {\n",
    "  \"$schema\": \"http://json-schema.org/draft-04/schema#\",\n",
    "  \"type\": \"object\",\n",
    "  \"properties\": {\n",
    "    \"editions\": {\n",
    "      \"type\": \"array\",\n",
    "      \"items\": [\n",
    "        {\n",
    "          \"type\": \"object\",\n",
    "          \"properties\": {\n",
    "            \"edition_name\": {\n",
    "              \"type\": \"string\"\n",
    "            },\n",
    "            \"title\": {\n",
    "              \"type\": \"string\"\n",
    "            },\n",
    "            \"author\": {\n",
    "              \"type\": \"string\"\n",
    "            },\n",
    "            \"editor\": {\n",
    "              \"type\": \"string\"\n",
    "            },\n",
    "            \"translator\": {\n",
    "              \"type\": \"string\"\n",
    "            },\n",
    "            \"assistant_translator\": {\n",
    "              \"type\": \"string\"\n",
    "            },\n",
    "            \"proprietor\": {\n",
    "              \"type\": \"string\"\n",
    "            },\n",
    "            \"publisher\": {\n",
    "              \"type\": \"string\"\n",
    "            },\n",
    "            \"printer\": {\n",
    "              \"type\": \"string\"\n",
    "            },\n",
    "            \"copyist\": {\n",
    "              \"type\": \"string\"\n",
    "            },\n",
    "            \"contents\": {\n",
    "              \"type\": \"string\"\n",
    "            },\n",
    "            \"place_of_publication\": {\n",
    "              \"type\": \"string\"\n",
    "            },\n",
    "            \"printing_medium\": {\n",
    "              \"type\": \"string\"\n",
    "            },\n",
    "            \"script\": {\n",
    "              \"type\": \"string\"\n",
    "            },\n",
    "            \"dimensions\": {\n",
    "              \"type\": \"string\"\n",
    "            },\n",
    "            \"extent\": {\n",
    "              \"type\": \"string\"\n",
    "            },\n",
    "            \"Notes\": {\n",
    "              \"type\": \"string\"\n",
    "            },\n",
    "            \"References\": {\n",
    "              \"type\": \"string\"\n",
    "            },\n",
    "            \"Location\": {\n",
    "              \"type\": \"string\"\n",
    "            },\n",
    "            \"unclassified_text\": {\n",
    "              \"type\": \"string\"\n",
    "            }\n",
    "          },\n",
    "          \"required\": [\n",
    "            \"edition_name\",\n",
    "            \"title\",\n",
    "            \"author\",\n",
    "            \"editor\",\n",
    "            \"translator\",\n",
    "            \"assistant_translator\",\n",
    "            \"proprietor\",\n",
    "            \"publisher\",\n",
    "            \"printer\",\n",
    "            \"copyist\",\n",
    "            \"contents\",\n",
    "            \"place_of_publication\",\n",
    "            \"printing_medium\",\n",
    "            \"script\",\n",
    "            \"dimensions\",\n",
    "            \"extent\",\n",
    "            \"Notes\",\n",
    "            \"References\",\n",
    "            \"Location\",\n",
    "            \"unclassified_text\"\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  },\n",
    "  \"required\": [\n",
    "    \"editions\"\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38faaaa-8ffb-4fa7-b966-aadfe4ab52a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_prompt(entry_text, book_title, json_schema):\n",
    "    prompt = f\"\"\"Please extract structured metadata from the following text. The text is an entry for a particular book from a catalogue of books printed before 1925 in Malaysia.\n",
    "    The text has been extracted from a pdf using optical character recognition and may contain errors. Do not correct these errors, but attempt to understand the correct words when extracting information.\n",
    "    The text is split using line breaks. These separate lines in the OCR, but extra, unnecessary line breaks have sometimes been added between text from the same line.\n",
    "    Each book entry begins with the book title, then is split into one or more editions. Each edition starts with an edition name in one of three formats:\n",
    "    1) A year\n",
    "    2) A year followed by a full stop then a letter (if there are multiple editions for one year)\n",
    "    3) A letter (if the date of publication is unknown)\n",
    "\n",
    "    The text for each edition normally reprints the edition date within it. The text for each edition contains different fields you should extract.\n",
    "    These fields are marked by the field heading, and fields may run over multiple lines. All text before the next field heading belongs to that field. Not every entry has every field.\n",
    "    Field headings are case insensitive. The Reference and Location fields are not usually followed by a colon. The other fields are followed by a colon.\n",
    "    Sometimes fields are combined, such as 'author & proprietor', or 'publisher & printer'. In these cases repeat the information in text in the author and proprietor fields of the output.\n",
    "    Field headings are:\n",
    "    - author\n",
    "    - editor\n",
    "    - translator\n",
    "    - assistant translator\n",
    "    - proprietor\n",
    "    - publisher\n",
    "    - printer\n",
    "    - copyist\n",
    "    - contents\n",
    "    - Notes\n",
    "    - Reference(s)\n",
    "    - Location(s)\n",
    "\n",
    "    There is text between the edition name and the first field. There may also be text between fields that does not belong to that field. Both these types of text should be treated together as follows.\n",
    "    This text may contain a title, a place of publication, the date of publication, the printing medium, the script of the text, the number of pages, the number of volumes, the dimensions of the edition.\n",
    "    If the title is missing use the title provided later on in this prompt, otherwise use the title from the text. Use this text to extract the following fields:\n",
    "    - title\n",
    "    - place_of_publication\n",
    "    - printing_medium\n",
    "    - script\n",
    "    - dimensions\n",
    "    - extent (the number of volumes and number of pages) \n",
    "    \n",
    "    Please extract the following information in json format. Only use the fields listed below. Not every entry has every field. If a field is missing represent it as <empty> in the output json.\n",
    "    - edition name\n",
    "    - title\n",
    "    - author\n",
    "    - editor\n",
    "    - translator\n",
    "    - assistant translator\n",
    "    - publisher\n",
    "    - printer\n",
    "    - copyist\n",
    "    - contents\n",
    "    - place_of_publication\n",
    "    - printing_medium\n",
    "    - script\n",
    "    - dimensions\n",
    "    - extent (the number of volumes and number of pages) \n",
    "    - notes\n",
    "    - references\n",
    "    - locations\n",
    "    Any text not in these fields include in the output json as a seperate field called 'unclassified_text'\n",
    "        \n",
    "    Please format the output as valid json using the schema below. Make sure to provide a valid and well-formatted JSON adhering to the given schema. Do not make up any information, only use what is provided in the text.\n",
    "    {json_schema}    \n",
    "\n",
    "    First, split the text into editions using the edition names, then assign the text for each edition to the appropriate fields.\n",
    "    The title of this book is: {book_title}\n",
    "    \n",
    "    Book entry text:\n",
    "    {entry_text}\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30162f1-d7e0-4cb4-9b30-41f559905ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, (_, title, _) in gt_entry_text_df.loc[:, [\"entry_text\", \"correct_title\", \"target_edition\"]].iterrows():\n",
    "#     fout = title.lower().replace(\" \", \"_\")\n",
    "#     with open(f\"../data/processed/model_outputs/{fout}.json\", \"w\") as f:\n",
    "#         f.write(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd8b42f-6b32-49b6-8cba-31d8883006b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, (text, title, target_ed) in gt_entry_text_df.loc[:, [\"entry_text\", \"correct_title\", \"target_edition\"]].iterrows():\n",
    "#     prompt = gen_prompt(entry_text=text, book_title=title, json_schema=json_schema)\n",
    "#     fout = title.lower().replace(\" \", \"_\")\n",
    "#     with open(f\"../models/prompts_outputs/{fout}_prompt.txt\", \"w\", encoding=\"utf8\") as f:\n",
    "#         f.write(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47570caa-3338-461c-aa87-c7a98515620d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_log = pd.read_csv(\"../models/prompts_outputs/prompt_output_log.csv\", encoding=\"utf8\", index_col=0)\n",
    "prompt_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5b6e75-884b-498b-9349-51b4a9fe6f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "550k token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35312e2c-47dc-4b65-872b-10378f222ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "661 * 250 + 372400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036a090d-6989-4b05-8894-f40362116387",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_loc_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10f9873-b90e-4b82-988b-d04d1c30ec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_loc_df[\"entry_text\"].str.replace(\"\\n\", \" \").apply(len).sum() * (250/918)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464636ad-70dc-49ee-9716-2fdcea47a0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prompt.split()[:-193])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb07a44-a493-4a8e-a219-013d3d9220a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "thinking = False\n",
    "model = \"Qwen3-235B-A22B-2507\"\n",
    "notes = \"entry text start fix\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011dcca5-56ec-46f0-a88b-98ba7392166e",
   "metadata": {},
   "source": [
    "#### Semi-auto logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f327dab-cec4-41d3-a4d5-e77ddcf86b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_logs = []\n",
    "for name, (text, title, target_ed) in gt_entry_text_df.loc[3:, [\"entry_text\", \"correct_title\", \"target_edition\"]].iterrows():\n",
    "    print(title)\n",
    "    prompt = gen_prompt(entry_text=text, book_title=title, json_schema=json_schema)\n",
    "    output = json.load(open(f\"../data/processed/model_outputs/{title.lower().replace(\" \", \"_\")}.json\"))\n",
    "    new_log = pd.DataFrame(data={'model': model, 'prompt': prompt, 'output': str(output), 'thinking': thinking, \"notes\": notes}, index=[prompt_log.index[-1] + 1])\n",
    "    new_logs.append(new_log)\n",
    "\n",
    "new_log_df = pd.concat(new_logs)\n",
    "updated_log = pd.concat([prompt_log, new_log_df]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d09d2f7-7878-405e-8ce6-b29c1b21b07d",
   "metadata": {},
   "source": [
    "#### Manual logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b0190e-a24f-432c-b26d-f8d1a8838358",
   "metadata": {},
   "outputs": [],
   "source": [
    "fout = \"sirat_al-mustakim\"\n",
    "\n",
    "with open(f\"../models/prompts_outputs/{fout}_prompt.txt\", encoding=\"utf8\") as f:\n",
    "        prompt = f.read()\n",
    "    \n",
    "output = json.load(open(f\"../data/processed/model_outputs/{fout}.json\"))\n",
    "\n",
    "new_log = pd.DataFrame(data={'model': model, 'prompt': prompt, 'output': str(output), 'thinking': thinking, \"notes\": notes}, index=[prompt_log.index[-1] + 1])\n",
    "updated_log = pd.concat([prompt_log, new_log])\n",
    "updated_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38226072-148c-4ace-a096-43391c85e3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_log.to_csv(\"../models/prompts_outputs/prompt_output_log.csv\", encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd63fa35-1ba0-4de7-b57d-94f9162d6540",
   "metadata": {},
   "source": [
    "#### Parse model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3da8590-656a-4837-90a0-ab9c6ecc6e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_entry_text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f6be3d-8b18-41a9-8bc5-69e65d3e2e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bl_shelfmark(location_str):\n",
    "    shelfmark_re = re.compile(r\"\\d+\\.[a-z]\\.[\\w()]+\")\n",
    "    locations = location_str.split(\";\")\n",
    "    bl_loc = [loc for loc in locations if \"BL\" in loc][0]\n",
    "    sm = shelfmark_re.search(bl_loc).group()\n",
    "    return sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546cdde0-4e67-4155-9f64-7e14a8910ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_lines = []\n",
    "for target_ed, title in gt_entry_text_df[[\"target_edition\", \"correct_title\"]].values:\n",
    "    output = json.load(open(f\"../data/processed/model_outputs/gt_outputs/{title.lower().replace(\" \", \"_\")}.json\"))\n",
    "    eds = [e[\"edition_name\"] for e in output[\"editions\"]]\n",
    "    print(eds)\n",
    "    for e in output[\"editions\"]:\n",
    "        if e[\"edition_name\"] == target_ed:\n",
    "            shelfmark = extract_bl_shelfmark(e[\"Location\"])\n",
    "            try:\n",
    "                date_1 = str(int(e[\"edition_name\"].split(\".\")[0]))\n",
    "                date_of_publication_in_arabic_or_roman_numerals = str(int(e[\"edition_name\"].split(\".\")[0]))\n",
    "            except ValueError:\n",
    "                date_1 = target_ed.split(\".\")[0]\n",
    "                date_of_publication_in_arabic_or_roman_numerals = target_ed.split(\".\")[0]\n",
    "            name = e[\"author\"]\n",
    "            extracted_title = e[\"title\"]\n",
    "            place_of_publication = e[\"place_of_publication\"]\n",
    "            publisher = e[\"publisher\"]\n",
    "            extent = e[\"extent\"]\n",
    "            dimensions = e[\"dimensions\"]\n",
    "            general_notes = e[\"printing_medium\"]\n",
    "            bibliography_etc_note = f\"Proudfoot 1993: {title} {e[\"edition_name\"]}\"\n",
    "            unclassified_text = e[\"unclassified_text\"]\n",
    "            method_of_acquisition = None\n",
    "\n",
    "            metadata = pd.DataFrame(\n",
    "                data={\n",
    "                    \"shelfmark\": shelfmark,\n",
    "                    \"date_1\": date_1,\n",
    "                    \"name\": name,\n",
    "                    \"title\": extracted_title,\n",
    "                    \"place_of_publication\": place_of_publication,\n",
    "                    \"publisher\": publisher,\n",
    "                    \"date_of_publication_in_arabic_or_roman_numerals\": date_of_publication_in_arabic_or_roman_numerals,\n",
    "                    \"extent\": extent,\n",
    "                    \"dimensions\": dimensions,\n",
    "                    \"general_notes\": general_notes,\n",
    "                    \"bibliography_etc_note\": bibliography_etc_note,\n",
    "                    \"method_of_acquisition\": method_of_acquisition,\n",
    "                    \"unclassified_text\": unclassified_text\n",
    "                },\n",
    "                index = [0]\n",
    "            )\n",
    "            metadata_lines.append(metadata)\n",
    "            break\n",
    "    else:\n",
    "        print(f\"{target_ed} absent for {title} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5cba7e-27b9-4558-8b77-fafa3f43ba43",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_lines_df = pd.concat(metadata_lines).sort_values(by=\"date_1\")\n",
    "metadata_lines_df.columns = ag_entry_gt_df.columns.to_list() + [\"Unclassified content\"]\n",
    "gt_comparison_df = pd.concat([raw_ag_entry_gt_df.loc[3:3], metadata_lines_df], sort=False).iloc[1:].loc[:, raw_ag_entry_gt_df.columns.to_list() + [\"Unclassified content\"]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaa894a-fa87-4a72-b2f9-ea4bd6d60af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727ff2de-c791-4da0-9a01-03d6939ae199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_comparison_df.to_csv(\"../data/processed/ground_truth_output_batch.csv\", index=False, encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1c7382-37f3-4b85-9e0c-8eb897bec0c4",
   "metadata": {},
   "source": [
    "Will likely have to have a second post-processing step where ask the model to extract putative publication location and publication date from the unclassified text if contained in square brackets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00a87c5-33ad-45d9-ae21-e670a6b731fd",
   "metadata": {},
   "source": [
    "### Parse non GT catalogue entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ab184e-4cc5-4c67-a3af-87bd6c68c8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "further_ten_sample = [\"Faiz al-Rahman 1894\",\n",
    "\"Abdau 1896\",\n",
    "\"Akidat al-Munajjin 1893\",\n",
    "\"Durrat al-Mudhiyat 1893\",\n",
    "\"Barzanji Makna Bugis 1896\",\n",
    "\"Maulud 1871.a\",\n",
    "\"Maulud 1871.b\",\n",
    "\"Safinah 1873.b\",\n",
    "\"Saif Allah 1900\",\n",
    "\"Ghayat al-Takrib 1893\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e397efc-8a36-4e86-a60a-2a1a608fb043",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.DataFrame(further_ten_sample)\n",
    "sample_df.columns = [\"raw_text\"]\n",
    "\n",
    "sample_df[\"target_title\"] = sample_df[\"raw_text\"].apply(lambda x: \" \".join(x.split()[:-1]))\n",
    "sample_df[\"target_edition\"] = sample_df[\"raw_text\"].apply(lambda x: x.split()[-1])\n",
    "sample_df.drop(columns=\"raw_text\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be706f3-c1ee-4976-b428-43ad168f2305",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_gt_entry_text_df = pd.merge(left=raw_entry_text_df, right=sample_df, left_on=\"correct_title\", right_on=\"target_title\")\n",
    "non_gt_entry_text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a33b2ab-3999-419d-866e-4b3ef99f9c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, (text, title, target_ed) in non_gt_entry_text_df.loc[:, [\"entry_text\", \"correct_title\", \"target_edition\"]].iterrows():\n",
    "    prompt = gen_prompt(entry_text=text, book_title=title, json_schema=json_schema)\n",
    "    fout = title.lower().replace(\" \", \"_\")\n",
    "    with open(f\"../models/prompts_outputs/{fout}_prompt.txt\", \"w\", encoding=\"utf8\") as f:\n",
    "        f.write(prompt)\n",
    "    # with open(f\"../data/processed/model_outputs/{fout}.json\", \"w\") as f:\n",
    "    #     f.write(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43d3b27-40a3-4903-9222-61de57aaa6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_gt_metadata_lines = []\n",
    "for target_ed, title in non_gt_entry_text_df[[\"target_edition\", \"correct_title\"]].values:\n",
    "    output = json.load(open(f\"../data/processed/model_outputs/non_gt_outputs/{title.lower().replace(\" \", \"_\")}.json\"))\n",
    "    \n",
    "    eds = [e[\"edition_name\"] for e in output[\"editions\"]]\n",
    "    print(eds)\n",
    "    for e in output[\"editions\"]:\n",
    "        if e[\"edition_name\"] == target_ed:\n",
    "            try:\n",
    "                shelfmark = extract_bl_shelfmark(e[\"Location\"])\n",
    "            except AttributeError:\n",
    "                shelfmark = None\n",
    "            try:\n",
    "                date_1 = str(int(e[\"edition_name\"].split(\".\")[0]))\n",
    "                date_of_publication_in_arabic_or_roman_numerals = str(int(e[\"edition_name\"].split(\".\")[0]))\n",
    "            except ValueError:\n",
    "                date_1 = target_ed.split(\".\")[0]\n",
    "                date_of_publication_in_arabic_or_roman_numerals = target_ed.split(\".\")[0]\n",
    "            name = e[\"author\"]\n",
    "            extracted_title = e[\"title\"]\n",
    "            place_of_publication = e[\"place_of_publication\"]\n",
    "            publisher = e[\"publisher\"]\n",
    "            extent = e[\"extent\"]\n",
    "            dimensions = e[\"dimensions\"]\n",
    "            general_notes = e[\"printing_medium\"]\n",
    "            bibliography_etc_note = f\"Proudfoot 1993: {title} {e[\"edition_name\"]}\"\n",
    "            unclassified_text = e[\"unclassified_text\"]\n",
    "            method_of_acquisition = None\n",
    "\n",
    "            metadata = pd.DataFrame(\n",
    "                data={\n",
    "                    \"shelfmark\": shelfmark,\n",
    "                    \"date_1\": date_1,\n",
    "                    \"name\": name,\n",
    "                    \"title\": extracted_title,\n",
    "                    \"place_of_publication\": place_of_publication,\n",
    "                    \"publisher\": publisher,\n",
    "                    \"date_of_publication_in_arabic_or_roman_numerals\": date_of_publication_in_arabic_or_roman_numerals,\n",
    "                    \"extent\": extent,\n",
    "                    \"dimensions\": dimensions,\n",
    "                    \"general_notes\": general_notes,\n",
    "                    \"bibliography_etc_note\": bibliography_etc_note,\n",
    "                    \"method_of_acquisition\": method_of_acquisition,\n",
    "                    \"unclassified_text\": unclassified_text\n",
    "                },\n",
    "                index = [0]\n",
    "            )\n",
    "            non_gt_metadata_lines.append(metadata)\n",
    "            break\n",
    "    else:\n",
    "        print(f\"{target_ed} absent for {title} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7102338b-bb4d-42df-bfe6-a8bb7ce024c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_gt_metadata_lines_df = pd.concat(non_gt_metadata_lines).sort_values(by=\"date_1\")\n",
    "non_gt_metadata_lines_df.columns = ag_entry_gt_df.columns.to_list() + [\"Unclassified content\"]\n",
    "non_gt_comparison_df = pd.concat([raw_ag_entry_gt_df.loc[3:3], non_gt_metadata_lines_df], sort=False).iloc[1:].loc[:, raw_ag_entry_gt_df.columns.to_list() + [\"Unclassified content\"]].reset_index(drop=True)\n",
    "non_gt_comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faf1fc9-b7c8-4e54-b049-f4818c144db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_gt_comparison_df.to_csv(\"../data/processed/non_ground_truth_output_batch.csv\", encoding=\"utf8\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1d48fe-f61b-4ceb-84df-d27cc908f59b",
   "metadata": {},
   "source": [
    "#### Get AG's columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa61387e-5953-49ac-a427-63b1aef57ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alphabet = {l:i for i,l in enumerate(sorted(list(set(full_desc)))[33:59])}\n",
    "\n",
    "alphabet = {\n",
    "    'A': 0,\n",
    "    'B': 1,\n",
    "    'C': 2,\n",
    "    'D': 3,\n",
    "    'E': 4,\n",
    "    'F': 5,\n",
    "    'G': 6,\n",
    "    'H': 7,\n",
    "    'I': 8,\n",
    "    'J': 9,\n",
    "    'K': 10,\n",
    "    'L': 11,\n",
    "    'M': 12,\n",
    "    'N': 13,\n",
    "    'O': 14,\n",
    "    'P': 15,\n",
    "    'Q': 16,\n",
    "    'R': 17,\n",
    "    'S': 18,\n",
    "    'T': 19,\n",
    "    'U': 20,\n",
    "    'V': 21,\n",
    "    'W': 22,\n",
    "    'X': 23,\n",
    "    'Y': 24,\n",
    "    'Z': 25\n",
    "}\n",
    "\n",
    "sample_df = pd.read_csv(\"../data/external/ALEPH_sample_Bollinger_EMP.csv\", encoding=\"utf8\")\n",
    "sample_df.drop(index=2, inplace=True)\n",
    "cols = [\"A\", \"E\", \"Q\", \"U\", \"AB\", \"AC\", \"AD\", \"AH\", \"AJ\", \"AQ\", \"AR\", \"CM\"]\n",
    "col_nums = [0, 4, 16, 20, 27, 28, 29, 33, 35, 42, 43, 90]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d2cdc9-a92b-4d81-87a8-55e7ceae8ce2",
   "metadata": {},
   "source": [
    "All before 1887 purchased, 1888 onwards legal deposit - AG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22c3583-d5f0-4149-b992-f882d4d8815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_nums = []\n",
    "for c in cols:\n",
    "    if len(c) == 1:\n",
    "        col_nums += [alphabet[c]]\n",
    "    if len(c) == 2:\n",
    "        d1 = 26 * (alphabet[c[0]] + 1)\n",
    "        d2 = alphabet[c[1]]\n",
    "        col_nums += [d1 + d2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff08ad5-0275-4383-a243-52bdc40efe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d69a034-314d-4fe4-b365-25d28ddb24e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.columns[col_nums]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddb6c7c-24a9-4b0f-a7a1-ccfaba6124f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df = sample_df.iloc[2:, col_nums].copy()\n",
    "gt_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
