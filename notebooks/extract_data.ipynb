{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a98a268-46ef-480c-ab8f-d4dd116e1818",
   "metadata": {},
   "source": [
    "# Extracting catalogue entries from the Early Malay Printed Books catalogue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19a2fe0-c80a-49b4-9153-02564b184992",
   "metadata": {},
   "source": [
    "Collaboration with Annabel Gallop and Adi Keinan-Schoonbaert to create catalogue entries from the OCR of the Early Malay Printed Books catalogue (EMP). Match the extracted entries to a set of works AG is digitising to provide skeleton metadata records as part of the digitisation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3409d7c0-cc62-4272-8dc8-9b4411d34ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "import json\n",
    "from random import sample\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import pymupdf\n",
    "from rapidfuzz import fuzz, utils, process\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946f89f4-c3df-4b2f-9d2f-dfff9e6fc7fa",
   "metadata": {},
   "source": [
    "## Extract Description section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe9a0eb-a1d3-47c3-b000-f90e3693dfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = pymupdf.open(\"../data/raw/emp.pdf\") # open a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd94e35-b7a6-438d-a5f5-b287f52b82b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cd2fc8-a27f-466d-b847-7b708dcf85a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = {\"desc\": {}, \"bl_list\": {}, \"titles\": {}}\n",
    "for i, page in enumerate(doc):\n",
    "    i = i + 1  # Just for ease when comparing indexing to the pdf pages\n",
    "    # Printed page numbers are the numbers printed on the page (from title page, then i - 858)\n",
    "    # Actual page numbers are the 1 - 886 numbers of the pages in the pdf, do not correspond to number on the page\n",
    "    # Remember that all actual page numbers in the pdf are one greater than the Python indexing\n",
    "    if i == 1:\n",
    "        section = None\n",
    "    if i == 126:  # Page 98\n",
    "        section = \"desc\"\n",
    "    if i == 596:  # Page 568\n",
    "        section = None\n",
    "    if i == 711:  # Page 683\n",
    "        section = \"titles\"\n",
    "    if i == 802:  # Page 774\n",
    "        break\n",
    "\n",
    "    if section:\n",
    "        page_num = i - 28\n",
    "        page_text = page.get_text() # get plain text (is in UTF-8)\n",
    "        text[section][i] = page_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e080da-cbf5-45bf-8cc6-a268af600d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(text[\"desc\"]) == 470\n",
    "assert len(text[\"titles\"]) == 91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a40deb4-01af-4bac-ae64-e3e07b9489bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_desc = \"\"\n",
    "for k, v in text[\"desc\"].items():\n",
    "    full_desc += v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b22db0-a259-44f8-b3fe-2b55735522c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(full_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a7175f-94b6-4e6e-9b26-c7ed0b545101",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/interim/full_description.txt\", \"w\", encoding=\"utf8\") as f:\n",
    "    f.write(full_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ee0861-3026-414b-82a4-4ae433a62cd4",
   "metadata": {},
   "source": [
    "### Tidy desc page text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35e1ebe-db9c-4253-ad42-a5487f3f0b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_header = []\n",
    "for i in range(126, 596, 2):\n",
    "    early_header.append(text[\"desc\"][i].split(\"\\n\")[0])\n",
    "\n",
    "desc_header = []\n",
    "for i in range(127, 597, 2):\n",
    "    desc_header.append(text[\"desc\"][i].split(\"\\n\")[0])\n",
    "\n",
    "has_page_num = []\n",
    "for i in range (126, 595):\n",
    "    has_page_num.append(text[\"desc\"][i].count(str(i - 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98995ccc-d85e-40c9-8880-0f96bdca162d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(has_page_num).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad68e15-090b-49d1-a7a4-4248ba5a282b",
   "metadata": {},
   "source": [
    "I've investigate the below, in each instance the header was not transcribed, rather than transcribed in the wrong place, so current logic to remove it if present holds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553bbacf-2d28-4e60-8037-2cc06d958b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(i, e) for i, e in enumerate(early_header) if \"EARL\" not in e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7f8336-3020-4e4e-b936-e06f13678342",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_head_counts = pd.Series([e for e in early_header if \"EARL\" in e]).value_counts()\n",
    "print(emp_head_counts.sum())\n",
    "emp_head_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c459d716-a3aa-4e59-877d-42bfa10437cd",
   "metadata": {},
   "source": [
    "The below is just some extra mistranscribed lines due to lines at the top of the photocopy, DESCRIPTION appears on the third line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bf4ceb-e14a-46c1-b9a0-5e4d9800bdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(i, d) for i, d in enumerate(desc_header) if \"DESC\" not in d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5902cee-4a7b-491d-b15f-ecff1881e37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([d for d in desc_header if \"DESC\" in d]).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0eb6e7f-a6e8-40f2-aabc-8302de504e63",
   "metadata": {},
   "source": [
    "#### Pre-treat mistranscriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce8445b-43a2-4a9c-a7d5-619a2f3e615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad header\n",
    "if text[\"desc\"][383][0] == \"_\":\n",
    "    text[\"desc\"][383] = text[\"desc\"][383][10:]\n",
    "assert text[\"desc\"][383][:5] == \"DESCR\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d22526e-69a6-41f5-90ce-e4b3d3d3f35e",
   "metadata": {},
   "source": [
    "#### Parsing the first page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471352f6-45a6-4b5a-8be9-d6f2d5b5efbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "split = text[\"desc\"][126].split(\"\\n\")\n",
    "if split[1] == \"It should be assumed that the author/editor \":\n",
    "    text[\"desc\"][126] = \"\\n\".join(split[9:49] + split[58:])\n",
    "assert text[\"desc\"][126][:5] == \"Abbas\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699bf135-8528-4a13-8dde-000aed540e7b",
   "metadata": {},
   "source": [
    "#### Parse columns on remaining pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0a2dd0-4d66-447f-8cdd-cc141912498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_desc_page(page, page_num):\n",
    "    trim_space = page.replace(\" \\n\", \"\\n\")\n",
    "    split = trim_space.split(\"\\n\")\n",
    "    lines = [l for l in split if l]\n",
    "    if \"DESC\" in lines[0] or \"EARL\" in lines[0]:\n",
    "        lines = lines[1:]\n",
    "\n",
    "    # Only 20 out of 469 pages where count != 1\n",
    "    if lines.count(page_num) == 1:\n",
    "        lines.remove(page_num)\n",
    "\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250416c8-c2c9-4a8e-aa37-e560b9a3d626",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_desc_pages = []\n",
    "for i in range(126, 596):\n",
    "    page_num = str(i - 28)\n",
    "    page = text[\"desc\"][i]\n",
    "    processed_desc_pages.append(process_desc_page(page=page, page_num=page_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0a2745-f2fa-4ffb-b199-16e46fa0b23e",
   "metadata": {},
   "source": [
    "#### Compare processed desc pages to ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0410af-6f74-421e-9d6a-dd2f29b3bbc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, p in enumerate(processed_desc_pages[:5]):\n",
    "    with open(f\"../data/processed/ground_truth/p{i+1}_column_parse.txt\", encoding=\"utf8\") as f:\n",
    "        gt = [l.strip(\"\\n\") for l in f.readlines()]\n",
    "        print(i + 1)\n",
    "        print([a for a,b in zip(gt, p) if a!=b])\n",
    "        assert gt == p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327e654f-18eb-4c13-90c1-0fac277ca4e3",
   "metadata": {},
   "source": [
    "## Extract catalogue entries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606ff8f1-1436-4580-a4da-744fae72771e",
   "metadata": {},
   "source": [
    "### Tidy title page text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383a7057-000a-4715-8513-195fadaa76b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_early_header = []\n",
    "for i in range(713, 802, 2):\n",
    "    titles_early_header.append(text[\"titles\"][i].split(\"\\n\")[0])\n",
    "\n",
    "titles_title_header = []\n",
    "for i in range(712, 802, 2):\n",
    "    titles_title_header.append(text[\"titles\"][i].split(\"\\n\")[0])\n",
    "\n",
    "titles_has_page_num = []\n",
    "for i in range (711, 802):\n",
    "    titles_has_page_num.append(text[\"titles\"][i].count(str(i - 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5126a5b-3dbc-45ee-84d4-cfe5b3149318",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(titles_has_page_num).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2f6b61-8d61-475e-a680-fd4fab8872d5",
   "metadata": {},
   "source": [
    "I've investigated the below, the page has been mis-transcribed as having two columns and needs correcting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ca8a6f-2e93-4d15-8d0c-7d7a25b1918c",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(i, e) for i, e in enumerate(titles_early_header) if \"EARL\" not in e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63db9dc2-cc8a-4941-8805-1faf4761fdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_head_counts = pd.Series([e for e in titles_early_header if \"EARL\" in e]).value_counts()\n",
    "print(emp_head_counts.sum())\n",
    "emp_head_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1313d343-7cb8-42aa-8695-44b47b2628b2",
   "metadata": {},
   "source": [
    "The below is just some extra mistranscribed lines due to lines at the top of the photocopy, DESCRIPTION appears on the third line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6ea9f2-1e95-4c87-847f-821c56bc0985",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(i, d) for i, d in enumerate(titles_title_header) if \"LES\" not in d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e8c749-c865-42f8-97e0-67a8734922be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([d for d in titles_title_header if \"LES\" in d]).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1a6e66-87a0-4c5d-92d5-679d6b0fd406",
   "metadata": {},
   "source": [
    "#### Pre-treat mistranscriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13d709c-0845-4d82-8bf5-09bcf3b7c5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad reading order\n",
    "text[\"titles\"][724] = text[\"titles\"][724].replace(\"\\nTITI..ES \", \"\")\n",
    "text[\"titles\"][768] = text[\"titles\"][768].replace(\"\\nTfILES \", \"\")\n",
    "text[\"titles\"][770] = text[\"titles\"][770].replace(\"\\nTI1LES \", \"\")\n",
    "text[\"titles\"][774] = text[\"titles\"][774].replace(\"\\nTITLES \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d583bf-3891-4065-a4d3-5f9727481bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text[\"titles\"][720][:1680]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3eb5d2-ded0-4b3b-8e93-ad771905d98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# semi-accidental double column\n",
    "# the excluded section contains no main works among collected ceretera/cerita/ceritera/cetera\n",
    "if text[\"titles\"][720][-5:] == \"692 \\n\":\n",
    "    text[\"titles\"][720] = text[\"titles\"][720][:1680]\n",
    "    \n",
    "# accidental double column\n",
    "# the small amount of extracted is the only main work among collected ceretera/cerita/ceritera/cetera\n",
    "if text[\"titles\"][721][:5] == '\"Chre':\n",
    "    text[\"titles\"][721] = text[\"titles\"][721][2613:2657].replace(\"\\n\", \"\")\n",
    "\n",
    "# accidental double columns\n",
    "# the small amount of extracted is the only main work among collected ceretera/cerita/ceritera/cetera\n",
    "if text[\"titles\"][722][:5] == \"TI1LE\":\n",
    "    text[\"titles\"][722] = \"Cerita Rampai-Rampai 1916 (t) - see also Abu Nawas 1917\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811299b7-611d-425f-8fe5-07c47e225c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "text[\"titles\"][722][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863a7875-0d25-468d-87d3-8035f787f86b",
   "metadata": {},
   "source": [
    "### Create list of titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb13082-e636-4f25-8cca-4a210c0c066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/processed/ground_truth/raw_title_list_p683.txt\", encoding=\"utf8\") as f:\n",
    "    raw_title_gt_lines_683 = [x.strip(\"\\n\") for x in f.readlines()]\n",
    "\n",
    "with open(\"../data/processed/ground_truth/raw_title_list_p688.txt\", encoding=\"utf8\") as f:\n",
    "    raw_title_gt_lines_688 = [x.strip(\"\\n\") for x in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae2d9d1-10f5-4cac-833c-53c371b910c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_titles_page(page, page_num):\n",
    "    # trim_space = page.replace(\" \\n\", \"\\n\")\n",
    "    continuing_date_p = re.compile(r\"\\n(\\d{4,4})\")\n",
    "    continue_date = continuing_date_p.sub(r\"\\1\", page)\n",
    "    continue_dash = continue_date.replace(\"\\n-\\n\", \"- \").replace(\"-\\n\", \"- \")\n",
    "    continue_a = continue_dash.replace(\"\\na \", \"a \").replace(\"\\na, \", \"a, \")\n",
    "    split = continue_a.split(\"\\n\")\n",
    "    lines = [l.strip() for l in split if l]\n",
    "\n",
    "    # Only 20 out of 469 pages where count != 1\n",
    "    if lines.count(page_num) == 1:\n",
    "        lines.remove(page_num)\n",
    "    \n",
    "    lines = lines[1:]\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54993a2e-b8e1-4935-b22d-8e27b5842692",
   "metadata": {},
   "outputs": [],
   "source": [
    "text[\"titles\"][711][833:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47feed79-c766-47dc-9c4e-3acbc5967242",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_title_pages = []\n",
    "for i in range(711, 802):\n",
    "    page_num = str(i - 28)\n",
    "    page = text[\"titles\"][i]\n",
    "    processed_title_pages.append(process_titles_page(page=page, page_num=page_num))\n",
    "\n",
    "processed_title_pages[0] = processed_title_pages[0][9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed52782-3329-4ca0-965f-0a4ec01eaa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(processed_title_pages[5]), len(raw_title_gt_lines_688)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bb3074-b30d-4911-b513-123ae9c81b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_titles = []\n",
    "for p in processed_title_pages:\n",
    "    all_titles.extend(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d52005f-8029-44f9-98c7-24013efb44f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13457a44-37aa-45a5-93a4-1c2e3c15e49f",
   "metadata": {},
   "source": [
    "#### Manual extraction of lines that should be concatenated but haven't"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c745b7-a68f-4ebd-995e-05f570533e4a",
   "metadata": {},
   "source": [
    "I went through all 4.3k title lines in all_titles and checked whether the line was a title or was a continuation of the previous line. Extracted all the lines that should be continued into lines_to_concatenate_with_text.  \n",
    "\n",
    "Decided this was a good trade-off as not too many lines to extract (~4% error) vs adding new rules to find these errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd038167-f6e5-4248-8062-93104850b4f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Used this to check all_titles 1k at a time, scanning quickly through the first letters of titles to check\n",
    "# took maybe half an hour\n",
    "[str(i + 0) + \" \" + t for i,t in enumerate(all_titles[0:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a18fb9-6208-414c-bcdc-9b88d3f20c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/processed/lines_to_concatenate_with_text.txt\", encoding=\"utf8\") as f:\n",
    "    lines = [l.strip(\"\\n\").split(\"\\t\") for l in f.readlines()]\n",
    "    bad_line_ids, bad_line_texts = [int(l[0]) for l in lines], [l[1] for l in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10e8743-f23f-4644-936f-2aed85d326c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the text of the lines we're going to merge with other lines matches our expectation\n",
    "assert all([all_titles[line_id] == text for line_id, text in zip(bad_line_ids, bad_line_texts)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c909d7e-3f17-4678-9bd1-c5ee269b1127",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check I've coded the lines right\n",
    "for l in bad_line_ids:\n",
    "    print(l)\n",
    "    print(\"\\n\".join(all_titles[l-2:l+3]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ea7d77-b36a-42af-84ab-c0a537a71f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_titles_concatenated = copy(all_titles)\n",
    "for l in bad_line_ids[::-1]:\n",
    "    all_titles_concatenated[l-1] = all_titles_concatenated[l-1] + \" \" + all_titles_concatenated[l]\n",
    "\n",
    "all_titles_corrected = []\n",
    "for i, t in enumerate(all_titles_concatenated):\n",
    "    if i not in bad_line_ids:\n",
    "        all_titles_corrected += [t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e14094c-4429-44a8-973e-09811c6d5014",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_titles_corrected[62]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7110511e-eea6-4f1d-8f94-6fe548d25caf",
   "metadata": {},
   "source": [
    "#### Select only main works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77779db3-d398-42d9-ab14-dbeb81544739",
   "metadata": {},
   "outputs": [],
   "source": [
    "see_re = re.compile(r\"see(?! also)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c432ca6b-b2db-4dc5-8bf5-87cf20825b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "see_re.search(\"hello see also\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddb793a-027b-43fc-ae96-524f64d6979d",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_works = []\n",
    "for title in all_titles_corrected:\n",
    "    if see_re.search(title) or \"look\" in title:\n",
    "        continue    \n",
    "    else:\n",
    "        main_works.append(title)\n",
    "\n",
    "# This cf is the only incorrect one not caught by the 'see' regex\n",
    "main_works.remove('Adab Kesopanan bagi Orang Muda-Muda Anak yang Bangsawan - cf Adab aI-Fatiy 1916')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8532a39-be9c-4544-bec5-92a589e1950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(main_works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e352b89-1ed1-44de-8a5a-ad964530eddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# template for gt based on first ~30 works\n",
    "\"\"\"\n",
    "with open(\"../data/processed/ground_truth/28_main_titles.txt\", \"w\", encoding=\"utf8\") as f:\n",
    "    for w in main_works[:30]:\n",
    "        f.write(w + \"\\n\")\n",
    "\"\"\"\n",
    "with open(\"../data/processed/ground_truth/28_main_titles.txt\", encoding=\"utf8\") as f:\n",
    "    gt_main_works = [l.strip(\"\\n\") for l in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75870664-e4d0-4b62-a06e-a7ed2aedf3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all([w == gt_w for w, gt_w in zip(main_works, gt_main_works)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4531eb-e825-4fc1-bae5-6554ea20f335",
   "metadata": {},
   "outputs": [],
   "source": [
    "works_date_re = re.compile(r\"[ ±]{1,2}[l0-9]{4,4}\")\n",
    "trailing_a_re = re.compile(r\" a( |$)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b518c11c-ba4f-4458-851b-0c8d8c9f28b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_work_short_titles = []\n",
    "for w in main_works:\n",
    "    no_date = re.split(works_date_re, w)[0]\n",
    "    no_a_ed = re.split(trailing_a_re, no_date)[0]\n",
    "    clean_short_title = no_a_ed\n",
    "    main_work_short_titles.append(clean_short_title)\n",
    "\n",
    "# Some work are duplicated due to line breaks converting \"see <name of work>\" to \"see\\n<name of work>\", in which case the work gets picked up again\n",
    "main_work_short_title_df = pd.Series(main_work_short_titles).drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef8e897-29d5-4718-9727-46a1efd7930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_work_short_title_df.to_csv(\"../data/processed/all_short_titles.csv\", encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b7d3f7-7c06-4f8b-8a47-8cfc9038367c",
   "metadata": {},
   "source": [
    "#### Compare main works to titles from BL shelf list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dabe81-37a6-4c26-aeba-cca7b225fe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aac_list = pd.read_csv(\"../data/external/Proudfoot-BL collection-6.10.25.csv\", header=None, names=[\"shelfmark\", \"short_title\", \"year\"], usecols=[0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f673b4f2-07a9-4169-acd7-58c54ce851b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trailing_abc_re = re.compile(r\" [abc] ?$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8030beb6-47d8-477d-a1d8-80de85cc4d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_short_title(row):\n",
    "    no_date = re.split(works_date_re, row[\"short_title\"])[0]\n",
    "    no_a_ed = re.split(trailing_abc_re, no_date)[0]\n",
    "    clean_short_title = no_a_ed\n",
    "    return clean_short_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f17b53-5e22-462d-b6bd-7caf34f0c851",
   "metadata": {},
   "outputs": [],
   "source": [
    "aac_list[\"short_title_no_year\"] = aac_list.apply(clean_short_title, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b74be19-8df5-43b5-a553-c29731ef9fde",
   "metadata": {},
   "source": [
    "435 unique titles in the AAC list. 174 of these don't appear identically in the main works list extracted from the titles list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69fbf80-4cca-4e68-b2f6-407967ba9818",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matched_works = [(w, w) for w in aac_list[\"short_title_no_year\"].unique() if w in main_work_short_titles]\n",
    "missing_works = [w for w in aac_list[\"short_title_no_year\"].unique() if w not in main_work_short_titles]\n",
    "len(missing_works), len(aac_list[\"short_title_no_year\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829d5588-c407-4ec8-80d0-4cfa68d1312c",
   "metadata": {},
   "source": [
    "Check all missing works from the AAC list against the entire main works list, using the basic rapidfuzz ration returning up to 3 matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01c56ac-cad6-421e-b045-c38ee726596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_work_matches = []\n",
    "for w in missing_works:\n",
    "    matches = process.extract(w, main_work_short_titles, scorer=fuzz.ratio, limit=3, processor=utils.default_process)\n",
    "    missing_work_matches.append([w, matches])\n",
    "\n",
    "accepted_matches = []\n",
    "failed_matches = []\n",
    "for w, matches in missing_work_matches:\n",
    "    if matches[0][1] >= 90:\n",
    "        accepted_matches.append((w, matches[0][0], matches[0][1]))\n",
    "    else:\n",
    "        failed_matches.append((w, matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504941de-0f8d-4492-b5c3-5ed499e18513",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(missing_works) - len(accepted_matches), len(accepted_matches), len(missing_works), len(aac_list[\"short_title_no_year\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7091806f-04f7-449d-8ec6-1de6ec6fbf47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accepted_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1081399c-a37a-444d-8c05-e6e6c11356cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "failed_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb99621-4aa5-4e7f-bc18-9dd826ecacc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_works += [(w[0], w[1]) for w in accepted_matches]\n",
    "matched_works.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fb5ce5-4971-4b13-bf0f-11d4689e52a9",
   "metadata": {},
   "source": [
    "#### Matched work ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30557bc2-77cc-4d62-8c7a-0825943e977c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = sample(matched_works, 50)\n",
    "# with open(\"../data/processed/ground_truth/50_matched_works.txt\", \"w\", encoding=\"utf8\") as f:\n",
    "#     for s in sample:\n",
    "#         f.write(f\"{s[0]}, {s[1]}\\n\")\n",
    "\n",
    "with open(\"../data/processed/ground_truth/50_matched_works.txt\", encoding=\"utf8\") as f:\n",
    "    gt_titles = [tuple(l.strip(\"\\n\").split(\", \")) for l in f.readlines()]\n",
    "    # gt_titles = [(w[0], w[1]) for w in ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72144a2-d39c-4773-81c0-4edfd9702751",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all([t in matched_works for t in gt_titles])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716acacf-6c0e-4113-8301-12b36094d511",
   "metadata": {},
   "source": [
    "### Create catalogue entry ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377c6216-2db4-42e6-8d4e-06bcc6975331",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_processed_lines = []\n",
    "line_page_lookup = {}\n",
    "line_count = 0\n",
    "for i, p in enumerate(processed_desc_pages):\n",
    "    all_processed_lines += p\n",
    "\n",
    "    for j, l in enumerate(p):\n",
    "        line_page_lookup[j + line_count] = i + 98\n",
    "    \n",
    "    line_count += len(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa04822-fee8-451f-8fda-4b8d9340c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate OCR errors from text in the GT\n",
    "entry_gt = {\n",
    "    \"Abbas\": all_processed_lines[1:42],\n",
    "    \"Abdau\": all_processed_lines[43:91],\n",
    "    \"Abdullah\": all_processed_lines[92:572],\n",
    "    \"Abdullah dan Sabat\": all_processed_lines[573:677],\n",
    "    \"AbdulMuluk\": all_processed_lines[678:1091]\n",
    "}\n",
    "\n",
    "# with open(\"../data/processed/ground_truth/entry.json\", \"w\", encoding=\"utf8\") as f:\n",
    "#     json.dump(entry_gt, f, indent=4)\n",
    "\n",
    "# with open(\"../data/processed/ground_truth/entry.json\", encoding=\"utf8\") as f:\n",
    "#     entry_gt = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d99353-0ed4-4c2f-b731-0f445fbbfb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, lines in entry_gt.items():\n",
    "    print(lines[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b5ef4d-e1ab-40c6-a639-0d0697e1b53b",
   "metadata": {},
   "source": [
    "### Search for main work short titles in all description lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505f3e46-2837-41ee-8de8-446e729fb13a",
   "metadata": {},
   "source": [
    "main_work_short_titles contains (to a degree of accuracy) all the short titles in the description section of the EMP. Use these to split up the lines of the description section into individual catalogue entries. Due to the quality of OCR in the description section I expect not to find a reasonable number of the main work short titles. Will have to use fuzzy string matching/manual intervention for the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82147e0a-e227-4957-9e43-67fce328eeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_locs = []\n",
    "title_line_tracker = 0  # This has to be accurate for it to work, otherwise can get too large too quickly\n",
    "# only use title_line_tracker as validity check once location of all headings confirmed\n",
    "\n",
    "# TODO work out longest entry to use that as a limit on how far ahead to search for the next heading\n",
    "# Answer: 2000 is ~2x the 95% of +ve valid hits using naive search algorithm (which includes some very large incorrect values)\n",
    "\n",
    "for w in main_work_short_title_df:\n",
    "    line_window = all_processed_lines[title_line_tracker: title_line_tracker + 2000]\n",
    "    if w in line_window:\n",
    "        line_loc = line_window.index(w) + title_line_tracker\n",
    "        title_locs.append((w, None, line_loc, title_line_tracker, title_line_tracker + 2000))\n",
    "        title_line_tracker = line_loc\n",
    "    else:\n",
    "        title_locs.append((w, None, None, title_line_tracker, title_line_tracker + 2000))\n",
    "\n",
    "title_loc_df = pd.DataFrame(title_locs, columns=[\"short_title\", \"short_title_ocr_alias\", \"line_start\", \"min_line\", \"max_line\"])\n",
    "title_loc_df[\"line_start\"] = title_loc_df[\"line_start\"].astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3268f256-0e07-41d2-a7e2-de0c69ea445e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just shy of 600 missing values at the moment\n",
    "title_loc_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6146f251-0579-4932-a486-15304ae8f94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_of_sequence_match = title_loc_df[\"line_start\"].dropna().iloc[:-1][~((title_loc_df[\"line_start\"].dropna().iloc[:-1] - title_loc_df[\"line_start\"].dropna().shift(-1)).dropna() < 0)]\n",
    "assert out_of_sequence_match.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda8a283-13b4-4d9d-bd7c-c885c46794f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_line(row, all_lines):\n",
    "    possible_lines = all_lines[row[\"min_line\"]:row[\"max_line\"]]\n",
    "    if row[\"line_start\"] is pd.NA:\n",
    "        nearest_line = process.extract(row[\"short_title\"], possible_lines, scorer=fuzz.ratio, limit=1, processor=utils.default_process)[0]\n",
    "        return (nearest_line[0], nearest_line[1], nearest_line[2] + row[\"min_line\"])\n",
    "    else:\n",
    "        return (row[\"short_title\"], 100.0, row[\"line_start\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42386092-23fb-45e1-8913-fa58811f07c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_apply = title_loc_df.apply(find_nearest_line, all_lines=all_processed_lines, axis=1)\n",
    "title_loc_df[\"nearest_line\"] = nearest_apply.apply(lambda x: x[0])\n",
    "title_loc_df[\"similarity\"] = nearest_apply.apply(lambda x: x[1])\n",
    "title_loc_df[\"nearest_line_idx\"] = nearest_apply.apply(lambda x: x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1df680-d508-464e-a0db-1a57519beffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# >90% similarity matches for 43% of unmatched names\n",
    "title_loc_df[\"similarity\"][title_loc_df[\"similarity\"] > 0].describe(percentiles=[0.57,0.6,0.65,0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09802844-bf38-47d7-b5b1-ea3fb61c0efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_loc_df.loc[title_loc_df[\"similarity\"] >= 90, \"short_title_ocr_alias\"] = title_loc_df.loc[title_loc_df[\"similarity\"] >= 90, \"short_title\"]\n",
    "title_loc_df.loc[title_loc_df[\"similarity\"] >= 90, \"line_start\"] = title_loc_df.loc[title_loc_df[\"similarity\"] >= 90, \"nearest_line_idx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca570338-4701-4948-b6e5-618fbdcb63d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After selecting >90% matches, 250 more matches, leaving 324 unmatched\n",
    "title_loc_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8626746-610d-4955-b236-69422e9f7e27",
   "metadata": {},
   "source": [
    "#### Manually check unmatched titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369b8c9b-3885-4b31-bfa1-c2508358b2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_with_adjacent = []\n",
    "for t in title_loc_df.loc[title_loc_df[\"line_start\"].isna()].index:\n",
    "    missing_with_adjacent += [t-1, t, t+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe155a2-a5d8-454a-899a-6ead36c7dcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_with_adjacent_df = title_loc_df.loc[sorted(list(set(missing_with_adjacent)))[:-1]]\n",
    "missing_with_adjacent_df[\"min_line_page\"] = missing_with_adjacent_df[\"min_line\"].map(line_page_lookup)\n",
    "missing_with_adjacent_df.to_csv(\"../data/interim/missing_title_adjacent.csv\", encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d773ae-c5df-41a3-965f-e4f64c6774db",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_with_adjacent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30a6112-6393-469f-bfc9-df2b71e1f714",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_check_df = pd.read_csv(\"../data/interim/missing_title_adjacent_manual_check.csv\", encoding=\"UTF8\", index_col=0)\n",
    "\n",
    "# check all missing titles have been manually checked\n",
    "assert manual_check_df[manual_check_df[\"line_start\"].isna()][\"approve\"][manual_check_df[manual_check_df[\"line_start\"].isna()][\"approve\"].isna()].empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc73a46-d6c9-43c3-b813-4b6165a20c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 55 incorrect, 25 to manually check\n",
    "manual_check_df[\"approve\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b273288c-7035-4b94-8344-51cfe3009aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "manually_approved_idx = manual_check_df[\"approve\"][manual_check_df[\"approve\"] == 1]\n",
    "\n",
    "title_loc_df.loc[manually_approved_idx.index, \"short_title_ocr_alias\"] = title_loc_df.loc[manually_approved_idx.index, \"nearest_line\"]\n",
    "title_loc_df.loc[manually_approved_idx.index, \"line_start\"] = title_loc_df.loc[manually_approved_idx.index, \"nearest_line_idx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be34905-369c-4207-b735-1ac3cfaa9b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_loc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dcb98b-a8c7-4862-93b3-eda18d99b675",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_loc_df[\"entry_start\"] = title_loc_df[\"nearest_line_idx\"]\n",
    "title_loc_df[\"entry_end\"] = title_loc_df[\"nearest_line_idx\"].shift(-1).astype(\"Int64\") - 1\n",
    "title_loc_df.iloc[-1, -1] = 51208  # Manually correct end of final entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee61db6-b930-4bba-9950-ff77f90e8a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_loc_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b19855-6e3c-4316-8f61-5d7c07504bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for gt_title, gt_text in entry_gt.items():\n",
    "    start, end = title_loc_df.query(f\"nearest_line == '{gt_title}'\")[[\"entry_start\", \"entry_end\"]].iloc[0]\n",
    "    extracted_text = all_processed_lines[start + 1:end + 1]\n",
    "    assert gt_text == extracted_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027f2cdd-c970-46bd-8e68-30be3e2d7cb5",
   "metadata": {},
   "source": [
    "Manual fix for a section that hadn't been picked up due to the title_line_tracker being pushed too far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7e23ff-3941-4ab0-a25e-15af8be8e698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual_title_locs = []\n",
    "# manual_title_line_tracker = 28825  # This has to be accurate for it to work, otherwise can get too large too quickly\n",
    "# # only use title_line_tracker as validity check once location of all headings confirmed\n",
    "\n",
    "# # TODO work out longest entry to use that as a limit on how far ahead to search for the next heading\n",
    "# # Answer: 2000 is ~2x the 95% of +ve valid hits using naive search algorithm (which includes some very large incorrect values)\n",
    "\n",
    "# for w in main_work_short_title_df.loc[505:525]:\n",
    "#     line_window = all_processed_lines[manual_title_line_tracker: manual_title_line_tracker + 2000]\n",
    "#     if w in line_window:\n",
    "#         line_loc = line_window.index(w) + manual_title_line_tracker\n",
    "#         manual_title_locs.append((w, None, line_loc, manual_title_line_tracker, manual_title_line_tracker + 2000))\n",
    "#         manual_title_line_tracker = line_loc\n",
    "#     else:\n",
    "#         manual_title_locs.append((w, None, None, manual_title_line_tracker, manual_title_line_tracker + 2000))\n",
    "\n",
    "# manual_title_loc_df = pd.DataFrame(manual_title_locs, columns=[\"short_title\", \"short_title_ocr_alias\", \"line_start\", \"min_line\", \"max_line\"])\n",
    "# manual_title_loc_df[\"line_start\"] = manual_title_loc_df[\"line_start\"].astype(\"Int64\")\n",
    "\n",
    "# manual_nearest_apply = manual_title_loc_df.apply(find_nearest_line, all_lines=all_processed_lines, axis=1)\n",
    "# manual_title_loc_df[\"nearest_line\"] = manual_nearest_apply.apply(lambda x: x[0])\n",
    "# manual_title_loc_df[\"similarity\"] = manual_nearest_apply.apply(lambda x: x[1])\n",
    "# manual_title_loc_df[\"nearest_line_idx\"] = manual_nearest_apply.apply(lambda x: x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e6e024-e5cc-4bf4-918e-c7f77e56d4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_processed_lines[51200:51208]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0b9939-8d07-441d-a123-2d381dc486c7",
   "metadata": {},
   "source": [
    "#### Check catalogue entry coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4d3e10-e960-4bc9-aa43-5692fcb56c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Easy manual approval reduces remaining to 81\n",
    "title_loc_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff73d193-de4f-42d2-93e3-6614ac8e607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_lines_set = set()\n",
    "for s in title_loc_df.dropna(subset=\"line_start\").apply(lambda x: set(range(x[\"entry_start\"], x[\"entry_end\"] + 1)), axis=1).values:\n",
    "    entry_lines_set |= s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405bdfe5-1336-4c04-b022-be5e94df8032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all but two lines included in title_loc_df entries\n",
    "print(len(all_processed_lines), len(entry_lines_set))\n",
    "set(range(0, 51207)) - entry_lines_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671dd531-e3a9-455c-8b8c-acd0d35cae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_processed_lines[26005: 26007]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe2b5cd-05e5-47a8-b1de-0d42d0defb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_loc_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25e4d2e-cf8f-4c0f-8d4a-fd0455af2f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_loc_df[\"entry_text\"] = title_loc_df.apply(lambda x: \"\\n\".join(all_processed_lines[x[\"entry_start\"]: x[\"entry_end\"] + 1]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f3cb3b-45c8-4a26-9a13-22d2f69eb5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prog_report_df = title_loc_df.rename(columns={\"short_title\": \"titles_ocr_short_title\", \"short_title_ocr_alias\": \"desc_ocr_short_title\"})[[\"titles_ocr_short_title\", \"desc_ocr_short_title\", \"entry_start\", \"entry_end\", \"entry_text\"]]\n",
    "# prog_report_df.to_csv(\"../data/processed/raw_entry_text.csv\", encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5502a3-99ee-46e0-b503-1fb8ac3fd482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prog_report_df = pd.read_csv(\"../data/processed/raw_entry_text.csv\", encoding=\"utf-8-sig\")\n",
    "prog_report_df.loc[3, \"entry_text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd82b0b-7d95-4c71-9b05-4957bee716e5",
   "metadata": {},
   "source": [
    "### Parse a catalogue entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e695d11-f7fd-48a0-ac74-1448c3317f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_text = \"\"\"Dmu Kepandalan a Bahwa Dunia ini Bulat adanya :ht1; [llmu Kepandaian :annat ifc] [Singapore] n.d. [after 21 Sya'ban 1255, October 1839] 73pp. (1-73 [last misnumbered \"37\"]); typeset jawi, on 22 x 14 cm pages, with 22 lines per page Contents: 1 Bahwa dunia ini bulat, 10 Fasal membuat kitab serta segala peta- peta, 14 ... menghimpunkan kitab- kitab, 18 ... menyatakan mengajar budak-budak miskin, 22 Pada menyatakan peri menerangkan rumah- rumah dan lorong-lorong di Eropah, 24 ... peri menjalankan air dalam segala rumah, 28 ... surat khabar, 31 ... perhimpunan wang, 34 Bagaimana membuat kitab dengan dicap, 46 Bahwa ini suatu jenis hikayat dalam negeri Eropah dan bagaimana gunanya, 57 Kebodohan puji-pujian yang tersebut dalam surat kiriman orang Melayu, 69 Pada menyatakan sifat udn Locations BL OIOC 14629.e.2; °BL OIOC [in process]; NLS RBS 500 ILM (Ql1.4/93) [as 1246, June 1830-June 1831] @ micro- form NL 7928 [microfilm incomplete: lacks 20-21]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c945c166-b364-45b4-a041-2b0d8fc54421",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e869f717-149f-49b8-8be1-9f67b0a89ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_schema = {\n",
    "  \"$schema\": \"http://json-schema.org/draft-04/schema#\",\n",
    "  \"type\": \"object\",\n",
    "  \"properties\": {\n",
    "    \"works\": {\n",
    "      \"type\": \"array\",\n",
    "      \"items\": [\n",
    "        {\n",
    "          \"type\": \"object\",\n",
    "          \"properties\": {\n",
    "            \"book_title\": {\n",
    "              \"type\": \"string\"\n",
    "            },\n",
    "            \"editions\": {\n",
    "              \"type\": \"array\",\n",
    "              \"items\": [\n",
    "                {\n",
    "                  \"type\": \"object\",\n",
    "                  \"properties\": {\n",
    "                    \"edition_date\": {\n",
    "                      \"type\": \"integer\"\n",
    "                    },\n",
    "                    \"edition_information\": {\n",
    "                      \"type\": \"object\",\n",
    "                      \"properties\": {\n",
    "                        \"author\": {\n",
    "                          \"type\": \"string\"\n",
    "                        },\n",
    "                        \"publisher\": {\n",
    "                          \"type\": \"string\"\n",
    "                        },\n",
    "                        \"printer\": {\n",
    "                          \"type\": \"string\"\n",
    "                        },\n",
    "                        \"copyist\": {\n",
    "                          \"type\": \"string\"\n",
    "                        },\n",
    "                        \"contents\": {\n",
    "                          \"type\": \"string\"\n",
    "                        },\n",
    "                        \"Notes\": {\n",
    "                          \"type\": \"string\"\n",
    "                        },\n",
    "                        \"References\": {\n",
    "                          \"type\": \"string\"\n",
    "                        },\n",
    "                        \"Location\": {\n",
    "                          \"type\": \"string\"\n",
    "                        },\n",
    "                        \"unclassified_text\": {\n",
    "                          \"type\": \"string\"\n",
    "                        }\n",
    "                      },\n",
    "                      \"required\": [\n",
    "                        \"author\",\n",
    "                        \"publisher\",\n",
    "                        \"printer\",\n",
    "                        \"copyist\",\n",
    "                        \"contents\",\n",
    "                        \"Notes\",\n",
    "                        \"References\",\n",
    "                        \"Location\",\n",
    "                        \"unclassified_text\"\n",
    "                      ]\n",
    "                    }\n",
    "                  },\n",
    "                  \"required\": [\n",
    "                    \"edition_date\",\n",
    "                    \"edition_information\"\n",
    "                  ]\n",
    "                }\n",
    "              ]\n",
    "            }\n",
    "          },\n",
    "          \"required\": [\n",
    "            \"book_title\",\n",
    "            \"editions\"\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  },\n",
    "  \"required\": [\n",
    "    \"works\"\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38faaaa-8ffb-4fa7-b966-aadfe4ab52a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_prompt(entry_text, json_schema):\n",
    "    prompt = f\"\"\"Please extract structured metadata from the following text. The text is an entry for a particular book title from a catalogue of books printed before 1925 in Malaysia.\n",
    "    Each book title entry is split into one or more editions, which are separated by a date explaining when the edition was published. Sometimes the date is missing, and the edition is marked by a letter.\n",
    "    \n",
    "    In particular, please provide the following information:\n",
    "    – A list of editions\n",
    "    - For each edition information about the edition, this is split into different fields. Only use the fields listed below and provide detailed descriptions for each entity. Not every entry has every field. If a field is missing represent it as <empty> in the output json.\n",
    "    The predefined fields are:\n",
    "    - author\n",
    "    - publisher\n",
    "    - printer\n",
    "    - copyist\n",
    "    - contents\n",
    "    - Notes\n",
    "    - References\n",
    "    - Location\n",
    "    Any text not in these fields include in the outputs as 'unclassified_text'\n",
    "        \n",
    "    Please format the output as valid json using the schema below:\n",
    "    {json_schema}\n",
    "    \n",
    "    Make sure to provide a valid and well-formatted JSON adhering to the given schema.  \n",
    "    \n",
    "    Content:\n",
    "    {entry_text}\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd8b42f-6b32-49b6-8cba-31d8883006b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = gen_prompt(entry_text, json_schema)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fac084-5797-4ba2-a9a8-439bd15128e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"Qwen/Qwen3-4B-Instruct-2507\"\n",
    "model_name = \"Qwen/Qwen3-1.7B\"\n",
    "\n",
    "# load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6448afdd-e0a8-459a-809c-fdfcb4f394d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(entry_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac0bac2-5083-44f0-8f35-c6fbc0c61e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "response: ChatResponse = chat(model='qwen3:1.7b', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': prompt,\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])\n",
    "# or access fields directly from the response object\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fb9083-9332-4f06-bc2f-b60d6aeb92c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dd871c-b7ee-4f4e-b330-f75852ae4cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the model input\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# conduct text completion\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=16384\n",
    ")\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n",
    "\n",
    "content = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "\n",
    "print(\"content:\", content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6018406d-6995-4dcf-8949-cde2efee4c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-generation\", model=\"Qwen/Qwen3-1.7B\")\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "]\n",
    "out = pipe(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fe86ee-88a2-4576-88dd-f742286df4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "out[0][\"generated_text\"][1][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8c990d-9164-4acc-b27c-b559a7753c09",
   "metadata": {},
   "source": [
    "#### Longest catalogue entry analysis to provide limit for difference between min_line and max_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddda781a-a4af-4d9f-82c6-902a66b80271",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_lengths = title_loc_df[\"line_start\"].iloc[1:] - title_loc_df[\"line_start\"].shift(1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ab57dc-af28-4266-8610-fc7b4ba3cdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_lengths[valid_lengths >= 0].dropna().describe(percentiles=[0.9,0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0525021-192d-4d8d-a3fa-9475955137b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_lengths[valid_lengths >= 0].dropna().hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d439920e-6cd3-40f3-9869-d750ddde2dfa",
   "metadata": {},
   "source": [
    "### Incu example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd732d31-f687-4bc9-9ff6-8699a72eea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_headings(lines: list[str]) -> tuple[list[str], list[list[int]], list[str]]:\n",
    "    \"\"\"\n",
    "    Finds all headings from a list of lines\n",
    "    :param lines: list[str]\n",
    "    :return: tuple[list[str], list[list[int]]\n",
    "    \"\"\"\n",
    "    sm_titles = []  # The names of the titles\n",
    "    title_indices = []\n",
    "    ordered_lines = copy(lines)\n",
    "    # TODO include the first catalogue entry as well\n",
    "    for i, l in enumerate(lines):\n",
    "        sm = find_shelfmark(l)\n",
    "        if sm:\n",
    "            title = [l]\n",
    "            title_index = []\n",
    "            j = 1\n",
    "            while i + j < len(lines) and j < 8:\n",
    "                title_part = lines[i + j]\n",
    "                if find_shelfmark(title_part):  # If a new catalogue entry begins during the current title\n",
    "                    break\n",
    "\n",
    "                title.append(title_part)\n",
    "                title_index.append(i + j)\n",
    "                j += 1\n",
    "\n",
    "                if date_check(title_part) and caps_regex.search(\" \". join(title)):  # Date marks the end of a heading\n",
    "                    sm_titles.append([sm, title])\n",
    "                    if \"Bought in\" in title[1]:  # not .lower() - these \"Bought in\" should all be capitalised\n",
    "                        sm, bought_in = lines[i], lines[i+1]\n",
    "                        ordered_lines[i], ordered_lines[i+1] = bought_in, sm\n",
    "                        title_indices.append(title_index[1:])\n",
    "                    else:\n",
    "                        title_indices.append(title_index)\n",
    "                    break\n",
    "\n",
    "    title_shelfmarks = [t[0] for t in sm_titles]\n",
    "\n",
    "    return title_shelfmarks, title_indices, ordered_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bf50f0-2169-4f5e-93c4-414e8efd3ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_pages[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70c890e-389a-4158-b35e-bae01ad54d62",
   "metadata": {},
   "source": [
    "### Look for letter page headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dec83b-3f86-4e8c-8e8d-e8b45c64e24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_re = re.compile(r\"^C\\s{0,2}$\", flags=re.MULTILINE)\n",
    "matches = []\n",
    "for k, v in text[\"desc\"].items():\n",
    "    if a_re.findall(v):\n",
    "        matches.append(v)\n",
    "\n",
    "print(len(matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9558ac0a-f906-443c-962e-62e79dcc74e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_lengths = pd.Series([len(v) for v in text[\"desc\"].values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768a07fe-8a8d-489d-9bde-c39c6ec4aec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_lengths.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eb131f-2f90-4739-92cc-2989f67b71aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[print(i, \"content:\", p) for i, p in text[\"desc\"].items() if len(p) < 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2755bd-2904-463b-8fc4-1ef5aefc4a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_re = re.compile(r\"^C\\s{0,2}$\", flags=re.MULTILINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1324d79-c62d-4cd2-9f79-be3a11ca29f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_re.findall(full_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1db78a7-34c9-443d-bad7-ce3c067e2ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_desc.split(\"\\nA \\n\")[1][-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73be18fb-af26-486e-a7e0-14b80ead8fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text[\"desc\"][1100:1300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bf6c82-0e34-469d-9ae8-3e83b0d486ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(text[\"desc\"][1100:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04993778-223b-420a-8034-e42179e629c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text[\"desc\"][-1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2eb1d1-a34a-4ab2-92f0-85e997f11359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(text[\"bl_list\"][:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6591d748-d123-4ae4-b1ec-59ae50aed172",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(text[\"bl_list\"][-1000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1d48fe-f61b-4ceb-84df-d27cc908f59b",
   "metadata": {},
   "source": [
    "#### Get AG's columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa61387e-5953-49ac-a427-63b1aef57ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alphabet = {l:i for i,l in enumerate(sorted(list(set(full_desc)))[33:59])}\n",
    "\n",
    "alphabet = {\n",
    "    'A': 0,\n",
    "    'B': 1,\n",
    "    'C': 2,\n",
    "    'D': 3,\n",
    "    'E': 4,\n",
    "    'F': 5,\n",
    "    'G': 6,\n",
    "    'H': 7,\n",
    "    'I': 8,\n",
    "    'J': 9,\n",
    "    'K': 10,\n",
    "    'L': 11,\n",
    "    'M': 12,\n",
    "    'N': 13,\n",
    "    'O': 14,\n",
    "    'P': 15,\n",
    "    'Q': 16,\n",
    "    'R': 17,\n",
    "    'S': 18,\n",
    "    'T': 19,\n",
    "    'U': 20,\n",
    "    'V': 21,\n",
    "    'W': 22,\n",
    "    'X': 23,\n",
    "    'Y': 24,\n",
    "    'Z': 25\n",
    "}\n",
    "\n",
    "sample_df = pd.read_csv(\"../data/external/ALEPH sample Bollinger EMP.csv\", encoding=\"utf8\", nrows=13)\n",
    "sample_df.drop(index=2, inplace=True)\n",
    "cols = [\"A\", \"E\", \"Q\", \"U\", \"AB\", \"AC\", \"AD\", \"AH\", \"AJ\", \"AQ\", \"AR\", \"CM\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d2cdc9-a92b-4d81-87a8-55e7ceae8ce2",
   "metadata": {},
   "source": [
    "All before 1887 purchased, 1888 onwards legal deposit - AG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22c3583-d5f0-4149-b992-f882d4d8815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_nums = []\n",
    "for c in cols:\n",
    "    if len(c) == 1:\n",
    "        col_nums += [alphabet[c]]\n",
    "    if len(c) == 2:\n",
    "        d1 = 26 * (alphabet[c[0]] + 1)\n",
    "        d2 = alphabet[c[1]]\n",
    "        col_nums += [d1 + d2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d69a034-314d-4fe4-b365-25d28ddb24e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.columns[col_nums]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddb6c7c-24a9-4b0f-a7a1-ccfaba6124f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df = sample_df.iloc[2:, col_nums].copy()\n",
    "gt_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
